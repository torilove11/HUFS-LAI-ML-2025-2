{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4CeT6ILSCYcc"
      },
      "outputs": [],
      "source": [
        "!pip install -q gdown transformers torch pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA1S2n086_Zl"
      },
      "source": [
        "##1. Google Drive에서 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpzJmO_83lkm",
        "outputId": "6c61fcd8-7094-4f5f-8ca0-f98cbcc0db86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading model from Google Drive (ID: 1iwRFkAnueiGc9SPCzylBbPavJZ163fSz)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1iwRFkAnueiGc9SPCzylBbPavJZ163fSz\n",
            "From (redirected): https://drive.google.com/uc?id=1iwRFkAnueiGc9SPCzylBbPavJZ163fSz&confirm=t&uuid=a98499ad-cf90-4049-ae57-7f10406934f5\n",
            "To: /content/assignment5_final_model.zip\n",
            "100%|██████████| 405M/405M [00:05<00:00, 70.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipping model...\n",
            "이중 폴더 감지됨. 파일을 상위로 이동합니다...\n",
            "모델 준비 완료. 폴더 구조가 정리되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "import shutil\n",
        "\n",
        "# https://drive.google.com/file/d/1iwRFkAnueiGc9SPCzylBbPavJZ163fSz/view?usp=drive_link\n",
        "file_id = '1iwRFkAnueiGc9SPCzylBbPavJZ163fSz'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output = 'assignment5_final_model.zip'\n",
        "extract_path = './assignment5_final_model'\n",
        "\n",
        "if os.path.exists(extract_path):\n",
        "    shutil.rmtree(extract_path)\n",
        "\n",
        "print(f\"Downloading model from Google Drive (ID: {file_id})...\")\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "print(\"Unzipping model...\") # 압축 해제\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# 압축 푼 폴더 내 확인\n",
        "inner_files = os.listdir(extract_path)\n",
        "\n",
        "# 이중 폴더가 생성되어 모델을 정상적으로 불러오지 못 해 이중 폴더 제거 코드 추가\n",
        "if len(inner_files) == 1 and inner_files[0] == 'assignment5_final_model':\n",
        "    nested_folder = os.path.join(extract_path, 'assignment5_final_model')\n",
        "    print(\"이중 폴더 감지됨. 파일을 상위로 이동합니다...\")\n",
        "\n",
        "    # 내부 폴더의 모든 파일을 상위로 이동\n",
        "    for file_name in os.listdir(nested_folder):\n",
        "        shutil.move(os.path.join(nested_folder, file_name), extract_path)\n",
        "\n",
        "    # 빈 내부 폴더 삭제\n",
        "    os.rmdir(nested_folder)\n",
        "\n",
        "print(\"모델 준비 완료. 폴더 구조가 정리되었습니다.\")\n",
        "\n",
        "if os.path.exists(output):\n",
        "    os.remove(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlN_TQJ2CgMh"
      },
      "source": [
        "## 2. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81jg8daDzzhD",
        "outputId": "23d0acb8-e740-40d9-ebbe-47bf19535ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Model from ./assignment5_final_model...\n",
            "Model Loaded Successfully!\n",
            "\n",
            "실제 추론 테스트 시작!\n",
            "\n",
            "입력: \"와 여기 진짜 인생 맛집입니다. 케이크가 촉촉하고 과일도 잔뜩 들었어요. 주문할 때 이것저것 여쭤봤는데 사장님도 정말 친절해요! 집에서 좀 먼데도 자주 올 것 같아요.\"\n",
            "결과: 긍정 (Positive) (확률: 99.93%)\n",
            "--------------------------------------------------\n",
            "입력: \"맛은 있네요. 고기가 질이 좋고 직원분이 고기도 다 구워주세요. 반찬도 다양하고 좋음. 그런데 가격이 비싸고 웨이팅도 길어서 특별한 날 말고는 안 올듯 싶네요.\"\n",
            "결과: 긍정 (Positive) (확률: 96.03%)\n",
            "--------------------------------------------------\n",
            "입력: \"인테리어 깔끔하고 자리가 넓어서 분위기는 예쁨. 그런데 메인이 생각보다 별로고 가격 대비 만족도가 떨어져서 굳이 재방문은 안 할듯. 근처에 비슷한 가격대에 더 맛있는 집 많음.\"\n",
            "결과: 부정 (Negative) (확률: 95.98%)\n",
            "--------------------------------------------------\n",
            "입력: \"멀리서 일부러 찾아올 정도는 아닌 것 같네요. 리뷰 괜찮아서 온 건데 다른 데 갈 걸 후회됩니다. 시간도 돈도 아까워요.\"\n",
            "결과: 부정 (Negative) (확률: 99.81%)\n",
            "--------------------------------------------------\n",
            "입력: \"가성비 오지네요. JMT!\"\n",
            "결과: 긍정 (Positive) (확률: 99.75%)\n",
            "--------------------------------------------------\n",
            "입력: \"The restaurant looked cozy and the staff were friendly. They greeted us with a smile. But the food itself was really disappointing. The main dish was a bit cold, and the side dishes tasted like they had been sitting out for a while.\"\n",
            "결과: 긍정 (Positive) (확률: 93.19%)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(np.int64(1), np.float32(93.188866))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 1. 모델 로드\n",
        "MODEL_PATH = './assignment5_final_model'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Loading Model from {MODEL_PATH}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"Model Loaded Successfully!\")\n",
        "\n",
        "# 2. 추론 함수 정의\n",
        "def predict_sentiment(text):\n",
        "    # 입력된 텍스트의 감성(긍정/부정)을 예측하고 확률을 반환\n",
        "    # 전처리 및 토크나이징\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=128,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    # GPU로 이동\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    # 추론\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # 확률 계산 (Softmax)\n",
        "    probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "    # 결과 해석\n",
        "    pred_label = probs.argmax()\n",
        "    confidence = probs[pred_label] * 100\n",
        "\n",
        "    label_map = {0: \"부정 (Negative)\", 1: \"긍정 (Positive)\"}\n",
        "    result = label_map[pred_label]\n",
        "\n",
        "    print(f\"입력: \\\"{text}\\\"\")\n",
        "    print(f\"결과: {result} (확률: {confidence:.2f}%)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return pred_label, confidence\n",
        "\n",
        "# 3. 실제 추론 테스트\n",
        "print(\"\\n실제 추론 테스트 시작!\\n\")\n",
        "\n",
        "# Case 1: 명확한 긍정\n",
        "predict_sentiment(\"와 여기 진짜 인생 맛집입니다. 케이크가 촉촉하고 과일도 잔뜩 들었어요. 주문할 때 이것저것 여쭤봤는데 사장님도 정말 친절해요! 집에서 좀 먼데도 자주 올 것 같아요.\")\n",
        "\n",
        "# Case 2: 전반적으로는 긍정이나 살짝 불만이 섞인 리뷰\n",
        "predict_sentiment(\"맛은 있네요. 고기가 질이 좋고 직원분이 고기도 다 구워주세요. 반찬도 다양하고 좋음. 그런데 가격이 비싸고 웨이팅도 길어서 특별한 날 말고는 안 올듯 싶네요.\")\n",
        "\n",
        "# Case 3: 전반적으로는 부정이나 살짝 칭찬이 섞인 리뷰\n",
        "predict_sentiment(\"인테리어 깔끔하고 자리가 넓어서 분위기는 예쁨. 그런데 메인이 생각보다 별로고 가격 대비 만족도가 떨어져서 굳이 재방문은 안 할듯. 근처에 비슷한 가격대에 더 맛있는 집 많음.\")\n",
        "\n",
        "# Case 4: 명확한 부정\n",
        "predict_sentiment(\"멀리서 일부러 찾아올 정도는 아닌 것 같네요. 리뷰 괜찮아서 온 건데 다른 데 갈 걸 후회됩니다. 시간도 돈도 아까워요.\")\n",
        "\n",
        "# Case 5: 신조어 (긍정)\n",
        "predict_sentiment(\"가성비 오지네요. JMT!\")\n",
        "\n",
        "# Case 6: 영어 리뷰 (부정)\n",
        "predict_sentiment(\"The restaurant looked cozy and the staff were friendly. They greeted us with a smile. But the food itself was really disappointing. The main dish was a bit cold, and the side dishes tasted like they had been sitting out for a while.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
