{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "202400190"
      ],
      "metadata": {
        "id": "146YkTamJAUk"
      },
      "id": "146YkTamJAUk"
    },
    {
      "cell_type": "markdown",
      "id": "8c96a48f",
      "metadata": {
        "id": "8c96a48f"
      },
      "source": [
        "# MNIST 손글씨 숫자 분류 튜토리얼\n",
        "\n",
        "이 노트북에서는 PyTorch를 사용하여 MNIST 데이터셋의 손글씨 숫자를 분류하는 간단한 Multi-Layer Perceptron (MLP) 모델을 구현합니다.\n",
        "\n",
        "## 학습 목표\n",
        "1. PyTorch를 이용한 기본적인 신경망 구현\n",
        "2. 데이터 로딩 및 전처리 과정 이해\n",
        "3. 모델 훈련 및 평가 과정 체험\n",
        "4. 예측 결과 시각화 및 분석\n",
        "\n",
        "## 데이터셋 정보\n",
        "- **MNIST**: 28x28 픽셀의 흑백 손글씨 숫자 이미지 (0-9)\n",
        "- **훈련 데이터**: 60,000개\n",
        "- **테스트 데이터**: 10,000개"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4uzj97p1jfe",
      "metadata": {
        "id": "4uzj97p1jfe"
      },
      "source": [
        "## 1. 라이브러리 임포트\n",
        "\n",
        "먼저 필요한 라이브러리들을 임포트합니다:\n",
        "\n",
        "- **torch**: PyTorch의 핵심 라이브러리\n",
        "- **torch.nn**: 신경망 레이어와 손실함수\n",
        "- **torch.optim**: 최적화 알고리즘 (Adam, SGD 등)\n",
        "- **torchvision.transforms**: 이미지 전처리\n",
        "- **datasets**: HuggingFace 데이터셋 라이브러리\n",
        "- **matplotlib**: 시각화\n",
        "- **numpy**: 수치 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3z7x9hct66v",
      "metadata": {
        "id": "3z7x9hct66v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ijq7kclsqrq",
      "metadata": {
        "id": "ijq7kclsqrq"
      },
      "source": [
        "## 2. MLP (Multi-Layer Perceptron) 모델 정의\n",
        "\n",
        "간단한 3층 신경망을 구현합니다:\n",
        "\n",
        "1. **입력층**: 784개 뉴런 (28×28 픽셀을 1차원으로 펼침)\n",
        "2. **은닉층**: 100개 뉴런 + ReLU 활성화 함수\n",
        "3. **출력층**: 10개 뉴런 (0-9 클래스)\n",
        "\n",
        "### 주요 개념:\n",
        "- **nn.Linear**: Fully Connected Layer (혹은 Dense Layer)\n",
        "- **nn.ReLU**: ReLU 활성화 함수 (음수는 0, 양수는 그대로)\n",
        "- **nn.Sequential**: 레이어들을 순차적으로 연결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "grc170711o7",
      "metadata": {
        "id": "grc170711o7"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=100, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),  # 784 -> 100\n",
        "            nn.ReLU(),                          # 활성화 함수\n",
        "            nn.Linear(hidden_size, num_classes) # 100 -> 10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        순전파 함수 // forward propagation\n",
        "        x: 입력 텐서 (batch_size, 784)\n",
        "        return: 출력 텐서 (batch_size, 10)\n",
        "        \"\"\"\n",
        "        return self.layers(x)\n",
        "\n",
        "# 모델 생성 및 구조 확인\n",
        "model = MLP()\n",
        "print(\"모델 구조:\")\n",
        "print(model)\n",
        "\n",
        "# 파라미터 개수 계산\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\n총 파라미터 수: {total_params:,}\")\n",
        "print(f\"학습 가능한 파라미터 수: {trainable_params:,}\")\n",
        "\n",
        "# 각 레이어별 파라미터 수 확인\n",
        "print(\"\\n레이어별 파라미터:\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.shape} ({param.numel():,} 개)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ut4tocwnhc",
      "metadata": {
        "id": "ut4tocwnhc"
      },
      "source": [
        "## 3. 데이터 로딩 및 전처리\n",
        "\n",
        "### 3.1 하이퍼파라미터 설정\n",
        "\n",
        "먼저 학습에 사용할 하이퍼파라미터들을 정의합니다:\n",
        "\n",
        "- **batch_size**: 한 번에 처리할 데이터의 개수\n",
        "- **learning_rate**: 학습률 (너무 크면 발산, 너무 작으면 학습이 느림)\n",
        "- **epochs**: 전체 데이터셋을 몇 번 반복할지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "so573tx44dm",
      "metadata": {
        "id": "so573tx44dm"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 128        # 배치 크기\n",
        "test_batch_size = 1000  # 테스트 배치 크기 (메모리 효율을 위해 크게 설정)\n",
        "learning_rate = 1e-3    # 학습률 (0.001)\n",
        "nb_epochs = 3           # 에포크 수\n",
        "\n",
        "print(\"=== 하이퍼파라미터 ===\")\n",
        "print(f\"배치 크기: {batch_size}\")\n",
        "print(f\"테스트 배치 크기: {test_batch_size}\")\n",
        "print(f\"학습률: {learning_rate}\")\n",
        "print(f\"에포크 수: {nb_epochs}\")\n",
        "\n",
        "# 디바이스 설정 (GPU가 있으면 GPU 사용)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\n사용 디바이스: {device}\")\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jkciy6jhkbj",
      "metadata": {
        "id": "jkciy6jhkbj"
      },
      "source": [
        "### 3.2 MNIST 데이터셋 로딩\n",
        "\n",
        "HuggingFace datasets 라이브러리를 사용하여 MNIST 데이터를 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "isbz53sgt4o",
      "metadata": {
        "id": "isbz53sgt4o"
      },
      "outputs": [],
      "source": [
        "# MNIST 데이터셋 로딩\n",
        "print(\"MNIST 데이터셋을 다운로드 중...\")\n",
        "mnist = load_dataset(\"mnist\")\n",
        "\n",
        "# 데이터셋 정보 출력\n",
        "print(\"\\n=== 데이터셋 정보 ===\")\n",
        "print(f\"훈련 데이터: {len(mnist['train']):,}개\")\n",
        "print(f\"테스트 데이터: {len(mnist['test']):,}개\")\n",
        "print(f\"클래스 수: {len(set(mnist['train']['label']))}개 (0-9)\")\n",
        "print(f\"이미지 크기: {mnist['train'][0]['image'].size}\")\n",
        "\n",
        "# 샘플 이미지 확인\n",
        "sample_image = mnist['train'][0]['image']\n",
        "sample_label = mnist['train'][0]['label']\n",
        "print(f\"\\n첫 번째 샘플: 라벨 {sample_label}\")\n",
        "\n",
        "# 클래스별 개수 확인\n",
        "from collections import Counter\n",
        "label_counts = Counter(mnist['train']['label'])\n",
        "print(\"\\n클래스별 데이터 개수:\")\n",
        "for i in range(10):\n",
        "    print(f\"숫자 {i}: {label_counts[i]:,}개\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "frspnwc8rwb",
      "metadata": {
        "id": "frspnwc8rwb"
      },
      "source": [
        "### 3.3 샘플 데이터 시각화\n",
        "\n",
        "학습하기 전에 데이터가 어떻게 생겼는지 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uj8obxszxp",
      "metadata": {
        "id": "uj8obxszxp"
      },
      "outputs": [],
      "source": [
        "# 샘플 이미지들 시각화\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    # 각 숫자(0-9)에 대해 첫 번째 샘플 찾기\n",
        "    for j, label in enumerate(mnist['train']['label']):\n",
        "        if label == i:\n",
        "            image = mnist['train'][j]['image']\n",
        "            axes[i].imshow(image, cmap='gray')\n",
        "            axes[i].set_title(f'Digit {i}')\n",
        "            axes[i].axis('off')\n",
        "            break\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('MNIST Dataset Samples (First image of each digit)', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vgb7ayrtxc",
      "metadata": {
        "id": "vgb7ayrtxc"
      },
      "source": [
        "### 3.4 데이터 정규화 (Normalization)\n",
        "\n",
        "신경망의 학습을 안정화하기 위해 픽셀 값을 정규화합니다:\n",
        "1. 픽셀 값을 0-1 범위로 변환 (ToTensor())\n",
        "2. 평균과 표준편차를 이용해 정규화 (Normalize())\n",
        "\n",
        "정규화 공식: `(픽셀값 - 평균) / 표준편차`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f34pdhxwn5c",
      "metadata": {
        "id": "f34pdhxwn5c"
      },
      "outputs": [],
      "source": [
        "# 데이터셋의 평균과 표준편차 계산 (1000개 샘플로 추정)\n",
        "print(\"데이터셋의 통계 정보를 계산 중...\")\n",
        "sample_data = torch.stack([\n",
        "    transforms.ToTensor()(mnist['train'][i]['image'])\n",
        "    for i in range(1000)\n",
        "])\n",
        "\n",
        "mean = sample_data.mean().item()\n",
        "std = sample_data.std().item()\n",
        "print(f\"평균(mean): {mean:.4f}\")\n",
        "print(f\"표준편차(std): {std:.4f}\")\n",
        "\n",
        "# Transform 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),           # PIL Image -> Tensor, 0-255 -> 0-1\n",
        "    transforms.Normalize((mean,), (std,))  # 정규화\n",
        "])\n",
        "\n",
        "print(\"\\n변환 파이프라인:\")\n",
        "print(\"1. ToTensor(): PIL Image -> PyTorch Tensor (0-255 -> 0-1)\")\n",
        "print(f\"2. Normalize(): (픽셀값 - {mean:.4f}) / {std:.4f}\")\n",
        "\n",
        "# 변환 전후 비교\n",
        "original_pixel = mnist['train'][0]['image']\n",
        "transformed = transform(original_pixel)\n",
        "print(f\"\\n변환 예시:\")\n",
        "print(f\"원본 픽셀 범위: 0-255\")\n",
        "print(f\"ToTensor 후: 0-1\")\n",
        "print(f\"정규화 후 범위: 약 {transformed.min():.2f} ~ {transformed.max():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h3ec7al6cl",
      "metadata": {
        "id": "h3ec7al6cl"
      },
      "source": [
        "### 3.5 DataLoader 생성\n",
        "\n",
        "DataLoader는 데이터를 배치 단위로 불러오고, 셔플링 등의 기능을 제공합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6wfdp8efmyf",
      "metadata": {
        "id": "6wfdp8efmyf"
      },
      "outputs": [],
      "source": [
        "# 데이터 변환 함수 정의\n",
        "def transform_dataset(dataset):\n",
        "    \"\"\"데이터셋에 변환을 적용하는 함수\"\"\"\n",
        "    def transform_fn(batch):\n",
        "        # 이미지를 텐서로 변환하고 28x28을 784로 평탄화\n",
        "        images = [transform(img).view(-1) for img in batch[\"image\"]]\n",
        "        return {\n",
        "            \"image\": torch.stack(images),\n",
        "            \"label\": torch.tensor(batch[\"label\"])\n",
        "        }\n",
        "    return dataset.with_transform(transform_fn)\n",
        "\n",
        "# 훈련/테스트 데이터셋에 변환 적용\n",
        "print(\"데이터셋 변환 중...\")\n",
        "train_dataset = transform_dataset(mnist[\"train\"])\n",
        "test_dataset = transform_dataset(mnist[\"test\"])\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True  # 훈련 데이터는 섞기\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False  # 테스트 데이터는 순서 유지\n",
        ")\n",
        "\n",
        "print(f\"훈련 DataLoader: {len(train_loader)}개 배치\")\n",
        "print(f\"테스트 DataLoader: {len(test_loader)}개 배치\")\n",
        "print(f\"배치당 훈련 샘플: {batch_size}개\")\n",
        "print(f\"배치당 테스트 샘플: {test_batch_size}개\")\n",
        "\n",
        "# 첫 번째 배치 확인\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\n첫 번째 배치 shape:\")\n",
        "print(f\"이미지: {sample_batch['image'].shape}  # (batch_size, 784)\")\n",
        "print(f\"라벨: {sample_batch['label'].shape}    # (batch_size,)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6gulko7i5ql",
      "metadata": {
        "id": "6gulko7i5ql"
      },
      "source": [
        "## 4. 모델 훈련\n",
        "\n",
        "### 4.1 모델, 손실함수, 최적화기 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a41rghsht",
      "metadata": {
        "id": "65a41rghsht"
      },
      "outputs": [],
      "source": [
        "# 모델 초기화 (이전에 생성한 model 재사용하지 않고 새로 생성)\n",
        "model = MLP().to(device)  # 모델을 GPU로 이동 (있다면)\n",
        "\n",
        "# 손실함수: 다중 클래스 분류를 위한 CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 최적화기: Adam (적응적 학습률 알고리즘)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"=== 훈련 설정 ===\")\n",
        "print(f\"모델: {model.__class__.__name__}\")\n",
        "print(f\"손실함수: {criterion.__class__.__name__}\")\n",
        "print(f\"최적화기: {optimizer.__class__.__name__}\")\n",
        "print(f\"디바이스: {device}\")\n",
        "print(f\"모델 파라미터 수: {sum(p.numel() for p in model.parameters()):,}개\")\n",
        "\n",
        "# 훈련 설정 요약\n",
        "print(f\"\\n=== 훈련 정보 ===\")\n",
        "print(f\"전체 에포크: {nb_epochs}\")\n",
        "print(f\"배치 크기: {batch_size}\")\n",
        "print(f\"학습률: {learning_rate}\")\n",
        "print(f\"에포크당 배치 수: {len(train_loader)}\")\n",
        "print(f\"에포크당 훈련 샘플 수: {len(train_loader) * batch_size:,}\")\n",
        "print(f\"전체 훈련 스텝: {nb_epochs * len(train_loader):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k9waf7yaxd",
      "metadata": {
        "id": "k9waf7yaxd"
      },
      "source": [
        "### 4.2 훈련 루프 실행\n",
        "\n",
        "신경망 훈련의 기본 단계:\n",
        "1. **Forward Pass**: 입력 데이터를 모델에 통과시켜 예측값 계산\n",
        "2. **Loss 계산**: 예측값과 실제값의 차이(오차) 계산\n",
        "3. **Backward Pass**: 역전파를 통해 각 파라미터의 그래디언트 계산\n",
        "4. **Parameter Update**: 최적화기를 사용해 파라미터 업데이트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3sp9z37zxiw",
      "metadata": {
        "id": "3sp9z37zxiw"
      },
      "outputs": [],
      "source": [
        "# 훈련 과정 추적을 위한 리스트\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "print(\"=== 훈련 시작 ===\\n\")\n",
        "\n",
        "for epoch in range(nb_epochs):\n",
        "    # 훈련 모드로 설정\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        # 데이터를 디바이스로 이동\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 통계 업데이트\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        # 100 배치마다 중간 결과 출력\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            current_loss = running_loss / (batch_idx + 1)\n",
        "            current_acc = 100 * correct_train / total_train\n",
        "            print(f\"Epoch [{epoch+1}/{nb_epochs}], Batch [{batch_idx+1}/{len(train_loader)}]\")\n",
        "            print(f\"  Loss: {current_loss:.4f}, Train Acc: {current_acc:.2f}%\")\n",
        "\n",
        "    # 에포크 종료 후 훈련 통계\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_train_acc = 100 * correct_train / total_train\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_train_acc)\n",
        "\n",
        "    print(f\"\\nEpoch [{epoch+1}/{nb_epochs}] 훈련 완료:\")\n",
        "    print(f\"  평균 Loss: {epoch_loss:.4f}\")\n",
        "    print(f\"  훈련 정확도: {epoch_train_acc:.2f}%\")\n",
        "\n",
        "    # 테스트 정확도 계산\n",
        "    model.eval()  # 평가 모드로 설정\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
        "        for batch in test_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100 * correct_test / total_test\n",
        "    test_accuracies.append(test_acc)\n",
        "    print(f\"  테스트 정확도: {test_acc:.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(f\"\\n=== 훈련 완료 ===\")\n",
        "print(f\"최종 훈련 정확도: {train_accuracies[-1]:.2f}%\")\n",
        "print(f\"최종 테스트 정확도: {test_accuracies[-1]:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pqku2b8psyn",
      "metadata": {
        "id": "pqku2b8psyn"
      },
      "source": [
        "## 5. 결과 분석 및 시각화\n",
        "\n",
        "### 5.1 훈련 과정 시각화\n",
        "\n",
        "Loss와 정확도의 변화를 그래프로 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "icbqk30iqt",
      "metadata": {
        "id": "icbqk30iqt"
      },
      "outputs": [],
      "source": [
        "# 훈련 과정 시각화\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss 그래프\n",
        "epochs_range = range(1, nb_epochs + 1)\n",
        "ax1.plot(epochs_range, train_losses, 'b-', marker='o', linewidth=2, markersize=8)\n",
        "ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_xticks(epochs_range)\n",
        "\n",
        "# 정확도 그래프\n",
        "ax2.plot(epochs_range, train_accuracies, 'g-', marker='s', linewidth=2,\n",
        "         markersize=8, label='Train Accuracy')\n",
        "ax2.plot(epochs_range, test_accuracies, 'r-', marker='^', linewidth=2,\n",
        "         markersize=8, label='Test Accuracy')\n",
        "ax2.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.set_xticks(epochs_range)\n",
        "ax2.set_ylim(80, 100)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 최종 결과 요약\n",
        "print(\"=== 최종 결과 요약 ===\")\n",
        "print(f\"최종 훈련 Loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"최종 훈련 정확도: {train_accuracies[-1]:.2f}%\")\n",
        "print(f\"최종 테스트 정확도: {test_accuracies[-1]:.2f}%\")\n",
        "print(f\"과적합 정도: {train_accuracies[-1] - test_accuracies[-1]:.2f}% (훈련-테스트 정확도 차이)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7u31xib5xoj",
      "metadata": {
        "id": "7u31xib5xoj"
      },
      "source": [
        "### 5.2 예측 결과 시각화\n",
        "\n",
        "모델이 실제로 어떻게 예측하는지 샘플 이미지들을 확인해보겠습니다. 올바른 예측과 틀린 예측을 모두 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iujp87752wh",
      "metadata": {
        "id": "iujp87752wh"
      },
      "outputs": [],
      "source": [
        "# 예측 샘플 수집\n",
        "model.eval()\n",
        "correct_samples = []\n",
        "wrong_samples = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # 정확한 예측과 틀린 예측 분리\n",
        "        for i in range(len(imgs)):\n",
        "            if len(correct_samples) >= 7 and len(wrong_samples) >= 3:\n",
        "                break\n",
        "\n",
        "            sample = (imgs[i], labels[i], predicted[i], outputs[i])\n",
        "            if labels[i] == predicted[i] and len(correct_samples) < 7:\n",
        "                correct_samples.append(sample)\n",
        "            elif labels[i] != predicted[i] and len(wrong_samples) < 3:\n",
        "                wrong_samples.append(sample)\n",
        "\n",
        "        if len(correct_samples) >= 7 and len(wrong_samples) >= 3:\n",
        "            break\n",
        "\n",
        "# 시각화: 7개 맞춘 것 + 3개 틀린 것\n",
        "display_samples = correct_samples + wrong_samples\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (img, true_label, pred_label, output) in enumerate(display_samples):\n",
        "    # 28x28로 reshape (정규화된 상태)\n",
        "    img_display = img.cpu().view(28, 28)\n",
        "\n",
        "    # 정규화를 역변환 (시각화를 위해)\n",
        "    img_display = img_display * std + mean\n",
        "    img_display = torch.clamp(img_display, 0, 1)\n",
        "\n",
        "    axes[i].imshow(img_display, cmap='gray')\n",
        "\n",
        "    # 색상 설정: 맞으면 초록, 틀리면 빨강\n",
        "    color = 'green' if true_label == pred_label else 'red'\n",
        "    axes[i].set_title(f'True: {true_label.item()}, Pred: {pred_label.item()}', color=color, fontweight='bold')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Prediction Results (Green: Correct, Red: Wrong)', y=1.02, fontsize=16, fontweight='bold')\n",
        "plt.show()\n",
        "\n",
        "print(f\"올바른 예측: {len([s for s in display_samples if s[1] == s[2]])}개\")\n",
        "print(f\"틀린 예측: {len([s for s in display_samples if s[1] != s[2]])}개\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bzow5k6y57j",
      "metadata": {
        "id": "bzow5k6y57j"
      },
      "source": [
        "### 5.3 모델의 확신도 분석\n",
        "\n",
        "틀리게 예측한 경우, 모델이 각 클래스에 대해 얼마나 확신했는지 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7jz1pmdl16x",
      "metadata": {
        "id": "7jz1pmdl16x"
      },
      "outputs": [],
      "source": [
        "# 틀린 예측에 대한 상세 분석\n",
        "if wrong_samples:\n",
        "    wrong_img, wrong_true, wrong_pred, wrong_output = wrong_samples[0]\n",
        "\n",
        "    # 소프트맥스를 통해 확률로 변환\n",
        "    probabilities = torch.softmax(wrong_output, dim=0).cpu()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # 왼쪽: 틀린 예측 이미지\n",
        "    img_display = wrong_img.cpu().view(28, 28) * std + mean\n",
        "    img_display = torch.clamp(img_display, 0, 1)\n",
        "    ax1.imshow(img_display, cmap='gray')\n",
        "    ax1.set_title(f'Wrong Prediction Case\\\\nTrue: {wrong_true.item()}, Pred: {wrong_pred.item()}',\n",
        "                  color='red', fontsize=12, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # 오른쪽: 확률 분포\n",
        "    bars = ax2.bar(range(10), probabilities, alpha=0.7, color='lightblue', edgecolor='black')\n",
        "\n",
        "    # 실제 라벨과 예측 라벨 강조\n",
        "    bars[wrong_true.item()].set_color('green')\n",
        "    bars[wrong_pred.item()].set_color('red')\n",
        "\n",
        "    ax2.set_xlabel('Digit Class', fontsize=11)\n",
        "    ax2.set_ylabel('Probability', fontsize=11)\n",
        "    ax2.set_title('Model Confidence by Class', fontsize=12, fontweight='bold')\n",
        "    ax2.set_xticks(range(10))\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 범례 추가\n",
        "    from matplotlib.lines import Line2D\n",
        "    legend_elements = [Line2D([0], [0], color='green', lw=4, label=f'True Label ({wrong_true.item()})'),\n",
        "                       Line2D([0], [0], color='red', lw=4, label=f'Predicted ({wrong_pred.item()})')]\n",
        "    ax2.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 상위 3개 확률 출력\n",
        "    top3_probs, top3_indices = torch.topk(probabilities, 3)\n",
        "    print(\"\\\\n=== 모델의 상위 3개 예측 ===\")\n",
        "    for i, (prob, idx) in enumerate(zip(top3_probs, top3_indices)):\n",
        "        print(f\"{i+1}위: 숫자 {idx.item()} (확률: {prob.item()*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\\\n실제 라벨 {wrong_true.item()}의 확률: {probabilities[wrong_true.item()]*100:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"틀린 예측 샘플이 없습니다. 모델이 모든 테스트 샘플을 정확히 예측했습니다!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fiwvxodjr8",
      "metadata": {
        "id": "2fiwvxodjr8"
      },
      "source": [
        "## 6. 과제 및 실험\n",
        "\n",
        "### 💡 학습을 위한 실험 제안\n",
        "\n",
        "이제 기본 모델을 이해했으니, 다음과 같은 실험들을 해보세요:\n",
        "\n",
        "#### 🔧 **Try 1: 하이퍼파라미터 튜닝**\n",
        "- 학습률을 바꿔보세요 (`learning_rate = 1e-2`, `1e-4` 등)\n",
        "- 은닉층 크기를 조정해보세요 (`hidden_size = 50`, `200` 등)\n",
        "- 에포크 수를 늘려보세요 (`nb_epochs = 5` 또는 `10`)\n",
        "\n",
        "#### 🏗️ **Try 2: 모델 구조 개선**\n",
        "- 은닉층을 더 추가해보세요 (3층, 4층 신경망)\n",
        "- 다른 활성화 함수를 시도해보세요 (`nn.Tanh()`, `nn.Sigmoid()`)\n",
        "- Dropout을 추가해서 과적합을 방지해보세요\n",
        "\n",
        "#### 📈 **Try 3: 성능 분석**\n",
        "- Confusion Matrix 그리기\n",
        "- 클래스별 정확도 분석\n",
        "- 잘못 분류된 이미지들의 패턴 찾기\n",
        "\n",
        "### 📝 **실험 결과 기록하기**\n",
        "각 실험 후 다음을 기록해보세요:\n",
        "- 최종 테스트 정확도\n",
        "- 훈련 시간\n",
        "- 관찰된 패턴이나 인사이트"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "id": "R7Jsz_9wXoUh"
      },
      "id": "R7Jsz_9wXoUh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}