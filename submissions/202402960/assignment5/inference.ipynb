{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztvP0N56OvHN",
        "outputId": "e5256431-4195-4236-d785-e49605a1a411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Device: cuda\n",
            "PROJECT_DIR: /content/drive/MyDrive/spanish_verb_project\n",
            "DATA_PATH : /content/drive/MyDrive/spanish_verb_project/data.csv\n",
            "TEST_PATH : /content/drive/MyDrive/spanish_verb_project/test_dataset.csv\n",
            "MODEL_PATH: /content/drive/MyDrive/spanish_verb_project/best_model.pt\n",
            "Full data shape: (65927, 4)\n",
            "          verb        mood        tense person\n",
            "0     abandono  indicative      present    1sg\n",
            "1   abandonaré  indicative       future    1sg\n",
            "2   abandonaba  indicative    imperfect    1sg\n",
            "3     abandoné  indicative    preterite    1sg\n",
            "4  abandonaría  indicative  conditional    1sg\n",
            "Mood classes: ['imperative' 'indicative' 'subjunctive']\n",
            "Tense classes: ['conditional' 'conditional_perfect' 'future' 'future_perfect' 'imperfect'\n",
            " 'pluperfect' 'present' 'present_perfect' 'preterite' 'preterite_anterior']\n",
            "Person classes: ['1pl' '1sg' '2pl' '2sg' '3pl' '3sg']\n",
            "Vocab size: 34\n",
            "✓ best_model.pt 로드 완료\n",
            "Test data shape: (6593, 7)\n",
            "                  verb         mood       tense person  mood_id  tense_id  \\\n",
            "0         sobreviviste   indicative   preterite    2sg        1         8   \n",
            "1  habíais glorificado   indicative  pluperfect    2pl        1         5   \n",
            "2              convida   indicative     present    3sg        1         6   \n",
            "3             aprendan  subjunctive     present    3pl        2         6   \n",
            "4          agradecerás   indicative      future    2sg        1         2   \n",
            "\n",
            "   person_id  \n",
            "0          3  \n",
            "1          2  \n",
            "2          5  \n",
            "3          4  \n",
            "4          3  \n",
            "=== Test Set Performance ===\n",
            "Total samples: 6593\n",
            "Exact-match Accuracy: 0.8715\n",
            "Mood Accuracy:        0.9691\n",
            "Tense Accuracy:       0.9895\n",
            "Person Accuracy:      0.8981\n",
            "\n",
            "=== Inference Examples ===\n",
            "     hablaré  →  mood=indicative,  tense=future,  person=1sg\n",
            "  habláremos  →  mood=subjunctive,  tense=future,  person=1pl\n",
            "     comimos  →  mood=indicative,  tense=preterite,  person=1pl\n",
            "     vivirán  →  mood=indicative,  tense=future,  person=3pl\n"
          ]
        }
      ],
      "source": [
        "# 환경 설정 & 라이브러리 임포트\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")   # ← 드라이브 마운트\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/spanish_verb_project\"\n",
        "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
        "\n",
        "\n",
        "# 경로 설정 (training과 동일한 위치)\n",
        "DATA_PATH  = os.path.join(PROJECT_DIR, \"data.csv\")\n",
        "TEST_PATH  = os.path.join(PROJECT_DIR, \"test_dataset.csv\")\n",
        "MODEL_PATH = os.path.join(PROJECT_DIR, \"best_model.pt\")\n",
        "\n",
        "print(\"DATA_PATH :\", DATA_PATH)\n",
        "print(\"TEST_PATH :\", TEST_PATH)\n",
        "print(\"MODEL_PATH:\", MODEL_PATH)\n",
        "\n",
        "\n",
        "#데이터 로드 & 레이블 인코더/문자 사전 재구성\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Full data shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# (1) LabelEncoder: mood / tense / person\n",
        "mood_le = LabelEncoder()\n",
        "tense_le = LabelEncoder()\n",
        "person_le = LabelEncoder()\n",
        "\n",
        "df[\"mood_id\"]   = mood_le.fit_transform(df[\"mood\"])\n",
        "df[\"tense_id\"]  = tense_le.fit_transform(df[\"tense\"])\n",
        "df[\"person_id\"] = person_le.fit_transform(df[\"person\"])\n",
        "\n",
        "print(\"Mood classes:\", mood_le.classes_)\n",
        "print(\"Tense classes:\", tense_le.classes_)\n",
        "print(\"Person classes:\", person_le.classes_)\n",
        "\n",
        "# (2) 문자 사전 생성 (training과 동일)\n",
        "all_chars = set()\n",
        "for v in df[\"verb\"].astype(str):\n",
        "    all_chars.update(list(v.lower()))\n",
        "\n",
        "char_to_id = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "for i, ch in enumerate(sorted(all_chars), start=2):\n",
        "    char_to_id[ch] = i\n",
        "\n",
        "id_to_char = {v: k for k, v in char_to_id.items()}\n",
        "vocab_size = len(char_to_id)\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "\n",
        "#Char 기반 Multi-Head LSTM 모델 정의\n",
        "\n",
        "class CharLSTMMultiHead(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim,\n",
        "                 hidden_dim, num_layers,\n",
        "                 num_moods, num_tenses, num_persons,\n",
        "                 dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embed_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "\n",
        "        lstm_out_dim = hidden_dim * 2  # bidirectional\n",
        "\n",
        "        # 각 라벨별 head\n",
        "        self.mood_head = nn.Sequential(\n",
        "            nn.Linear(lstm_out_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_moods),\n",
        "        )\n",
        "        self.tense_head = nn.Sequential(\n",
        "            nn.Linear(lstm_out_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_tenses),\n",
        "        )\n",
        "        self.person_head = nn.Sequential(\n",
        "            nn.Linear(lstm_out_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_persons),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)            # (B, L, E)\n",
        "        out, (h_n, c_n) = self.lstm(emb)   # h_n: (num_layers*2, B, H)\n",
        "\n",
        "        # 마지막 레이어의 forward / backward hidden state 결합\n",
        "        h_forward  = h_n[-2]   # (B, H)\n",
        "        h_backward = h_n[-1]   # (B, H)\n",
        "        h = torch.cat([h_forward, h_backward], dim=1)  # (B, 2H)\n",
        "\n",
        "        mood_logits   = self.mood_head(h)\n",
        "        tense_logits  = self.tense_head(h)\n",
        "        person_logits = self.person_head(h)\n",
        "\n",
        "        return mood_logits, tense_logits, person_logits\n",
        "\n",
        "# 모델 객체 생성 (하이퍼파라미터는 training과 동일하게!)\n",
        "num_moods   = df[\"mood_id\"].nunique()\n",
        "num_tenses  = df[\"tense_id\"].nunique()\n",
        "num_persons = df[\"person_id\"].nunique()\n",
        "\n",
        "model = CharLSTMMultiHead(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=64,\n",
        "    hidden_dim=256,\n",
        "    num_layers=3,\n",
        "    num_moods=num_moods,\n",
        "    num_tenses=num_tenses,\n",
        "    num_persons=num_persons,\n",
        "    dropout=0.5,\n",
        ").to(device)\n",
        "\n",
        "# 저장된 가중치 로드\n",
        "state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "print(\"✓ best_model.pt 로드 완료\")\n",
        "\n",
        "\n",
        "#Test set 로드 & Dataset / DataLoader 정의\n",
        "\n",
        "MAX_LEN = 20\n",
        "\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "print(\"Test data shape:\", test_df.shape)\n",
        "print(test_df.head())\n",
        "\n",
        "# test_df에 id 라벨 추가 (training과 동일한 인코더 사용)\n",
        "test_df[\"mood_id\"]   = mood_le.transform(test_df[\"mood\"])\n",
        "test_df[\"tense_id\"]  = tense_le.transform(test_df[\"tense\"])\n",
        "test_df[\"person_id\"] = person_le.transform(test_df[\"person\"])\n",
        "\n",
        "class VerbDataset(Dataset):\n",
        "    def __init__(self, df, char_to_id, max_len=20):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.char_to_id = char_to_id\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        verb = str(row[\"verb\"]).lower()\n",
        "\n",
        "        ids = [self.char_to_id.get(ch, self.char_to_id[\"<UNK>\"]) for ch in verb]\n",
        "\n",
        "        if len(ids) < self.max_len:\n",
        "            ids += [self.char_to_id[\"<PAD>\"]] * (self.max_len - len(ids))\n",
        "        else:\n",
        "            ids = ids[:self.max_len]\n",
        "\n",
        "        x = torch.tensor(ids, dtype=torch.long)\n",
        "        y_mood   = torch.tensor(row[\"mood_id\"], dtype=torch.long)\n",
        "        y_tense  = torch.tensor(row[\"tense_id\"], dtype=torch.long)\n",
        "        y_person = torch.tensor(row[\"person_id\"], dtype=torch.long)\n",
        "\n",
        "        return x, y_mood, y_tense, y_person\n",
        "\n",
        "test_dataset = VerbDataset(test_df, char_to_id, max_len=MAX_LEN)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "\n",
        "#Test set에서 최종 성능 평가 (Exact-match 기준)\n",
        "\n",
        "def evaluate_on_test(model, loader, device):\n",
        "    model.eval()\n",
        "    total_samples = 0\n",
        "    exact_correct = 0\n",
        "\n",
        "    mood_correct = 0\n",
        "    tense_correct = 0\n",
        "    person_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y_mood, y_tense, y_person in loader:\n",
        "            x = x.to(device)\n",
        "            y_mood = y_mood.to(device)\n",
        "            y_tense = y_tense.to(device)\n",
        "            y_person = y_person.to(device)\n",
        "\n",
        "            out_mood, out_tense, out_person = model(x)\n",
        "\n",
        "            mood_pred   = out_mood.argmax(1)\n",
        "            tense_pred  = out_tense.argmax(1)\n",
        "            person_pred = out_person.argmax(1)\n",
        "\n",
        "            # 각 head별 정확도\n",
        "            mood_correct   += (mood_pred == y_mood).sum().item()\n",
        "            tense_correct  += (tense_pred == y_tense).sum().item()\n",
        "            person_correct += (person_pred == y_person).sum().item()\n",
        "\n",
        "            # 세 개 모두 맞은 경우 (Exact-match)\n",
        "            all_correct = (\n",
        "                (mood_pred == y_mood) &\n",
        "                (tense_pred == y_tense) &\n",
        "                (person_pred == y_person)\n",
        "            ).sum().item()\n",
        "\n",
        "            exact_correct += all_correct\n",
        "            total_samples += x.size(0)\n",
        "\n",
        "    exact_acc   = exact_correct / total_samples\n",
        "    mood_acc    = mood_correct / total_samples\n",
        "    tense_acc   = tense_correct / total_samples\n",
        "    person_acc  = person_correct / total_samples\n",
        "\n",
        "    print(\"=== Test Set Performance ===\")\n",
        "    print(f\"Total samples: {total_samples}\")\n",
        "    print(f\"Exact-match Accuracy: {exact_acc:.4f}\")\n",
        "    print(f\"Mood Accuracy:        {mood_acc:.4f}\")\n",
        "    print(f\"Tense Accuracy:       {tense_acc:.4f}\")\n",
        "    print(f\"Person Accuracy:      {person_acc:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"exact_acc\": exact_acc,\n",
        "        \"mood_acc\": mood_acc,\n",
        "        \"tense_acc\": tense_acc,\n",
        "        \"person_acc\": person_acc,\n",
        "    }\n",
        "\n",
        "test_scores = evaluate_on_test(model, test_loader, device)\n",
        "\n",
        "\n",
        "#단일 동사 추론 함수 정의\n",
        "\n",
        "def predict_verb_form(verb_str: str):\n",
        "    \"\"\"\n",
        "    입력: 스페인어 동사 한 형태 (예: 'hablaré')\n",
        "    출력: {'mood': ..., 'tense': ..., 'person': ...}\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    verb = verb_str.lower()\n",
        "    ids = [char_to_id.get(ch, char_to_id[\"<UNK>\"]) for ch in verb]\n",
        "\n",
        "    if len(ids) < MAX_LEN:\n",
        "        ids += [char_to_id[\"<PAD>\"]] * (MAX_LEN - len(ids))\n",
        "    else:\n",
        "        ids = ids[:MAX_LEN]\n",
        "\n",
        "    x = torch.tensor([ids], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out_mood, out_tense, out_person = model(x)\n",
        "\n",
        "    mood_id   = out_mood.argmax(1).item()\n",
        "    tense_id  = out_tense.argmax(1).item()\n",
        "    person_id = out_person.argmax(1).item()\n",
        "\n",
        "    # id → 원래 문자열 라벨로 변환\n",
        "    mood_label   = mood_le.inverse_transform([mood_id])[0]\n",
        "    tense_label  = tense_le.inverse_transform([tense_id])[0]\n",
        "    person_label = person_le.inverse_transform([person_id])[0]\n",
        "\n",
        "    return {\n",
        "        \"verb\": verb_str,\n",
        "        \"mood\": mood_label,\n",
        "        \"tense\": tense_label,\n",
        "        \"person\": person_label\n",
        "    }\n",
        "\n",
        "\n",
        "#예시 동사 추론\n",
        "\n",
        "examples = [\n",
        "    \"hablaré\",    # 직설법 미래 1sg\n",
        "    \"habláremos\", # 접속법 미래 1pl\n",
        "    \"comimos\",    # 직설법 과거 1pl\n",
        "    \"vivirán\",    # 직설법 미래 3pl\n",
        "]\n",
        "\n",
        "print(\"\\n=== Inference Examples ===\")\n",
        "for v in examples:\n",
        "    pred = predict_verb_form(v)\n",
        "    print(f\"{pred['verb']:>12}  →  mood={pred['mood']},  tense={pred['tense']},  person={pred['person']}\")\n"
      ]
    }
  ]
}