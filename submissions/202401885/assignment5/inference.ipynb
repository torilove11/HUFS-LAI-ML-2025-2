{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PtXdfzWADS3",
        "outputId": "c2d1e293-9674-481f-c243-b7873ae14084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "â³ ëª¨ë¸ ë¡œë”© ì¤‘...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer you are loading from '/content/drive/MyDrive/toefl_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e.  This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! (Regression Mode On)\n",
            "\n",
            "=== ğŸ“ TOEFL AI Scorer Demo ===\n",
            "\n",
            "[Case 1: High Quality Essay]\n",
            "â–¶ Predicted Score: 27.80 / 30.00\n",
            "\n",
            "[Case 2: Medium Quality Essay]\n",
            "â–¶ Predicted Score: 27.31 / 30.00\n",
            "\n",
            "[Case 3: Low Quality Essay]\n",
            "â–¶ Predicted Score: 17.96 / 30.00\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers torch\n",
        "\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from google.colab import drive\n",
        "import torch\n",
        "\n",
        "# ==========================================\n",
        "# 1. ëª¨ë¸ ë¡œë“œ (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)\n",
        "# ==========================================\n",
        "drive.mount('/content/drive')\n",
        "model_path = \"/content/drive/MyDrive/toefl_model\"\n",
        "\n",
        "print(\"â³ ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
        "\n",
        "try:\n",
        "    # 1. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì§ì ‘ ë¡œë“œ (ì•ˆì „ì¥ì¹˜)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    # [í•µì‹¬] function_to_apply=\"none\" ì¶”ê°€!\n",
        "    scorer = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, function_to_apply=\"none\")\n",
        "    print(\"âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! (Regression Mode On)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ê²½ê³ /ì—ëŸ¬ ë°œìƒ: {e}\")\n",
        "    print(\"âš ï¸ ê¸°ë³¸ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-small\", num_labels=1)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
        "    scorer = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, function_to_apply=\"none\")\n",
        "\n",
        "\n",
        "def predict_score(essay_text):\n",
        "    \"\"\"ì—ì„¸ì´ë¥¼ ì…ë ¥ë°›ì•„ ì ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (ìŠ¤ì¼€ì¼ ë³´ì • í¬í•¨)\"\"\"\n",
        "    # 1. ëª¨ë¸ ì˜ˆì¸¡ (512 í† í° ì œí•œ)\n",
        "    result = scorer(essay_text, truncation=True, max_length=512)\n",
        "    raw_score = result[0]['score']\n",
        "\n",
        "    # 2. ì ìˆ˜ ë³´ì • (Calibration)\n",
        "    final_score = raw_score * 3.5\n",
        "\n",
        "    # 3. ìµœëŒ€ 30ì , ìµœì†Œ 0ì ìœ¼ë¡œ ë²”ìœ„ ì œí•œ\n",
        "    final_score = min(30.0, max(0.0, final_score))\n",
        "\n",
        "    return final_score\n",
        "\n",
        "# ==========================================\n",
        "# 2. ì‹œì—°ìš© ì—ì„¸ì´ ì˜ˆì‹œ (Demo Cases)\n",
        "# ==========================================\n",
        "\n",
        "# Case 1: High Score (30ì  ë§Œì  ì˜ˆìƒ)\n",
        "essay_high = \"\"\"\n",
        "The lecturer argues that the plan to use bacteria to clean up the oil spill is not effective.\n",
        "First, the reading claims that the bacteria can break down the oil quickly. However, the lecturer points out that this process is only effective in warm waters. Since the spill occurred in a cold region, the bacteria would multiply too slowly to make a significant difference.\n",
        "Second, while the reading suggests that the bacteria are safe for the ecosystem, the lecturer refutes this by mentioning that the large number of bacteria could disrupt the local food chain.\n",
        "This clearly demonstrates that the proposed solution has significant flaws when applied to real-world scenarios. The logic provided by the lecturer effectively counters the reading passage's optimistic view.\n",
        "\"\"\"\n",
        "\n",
        "# Case 2: Medium Score (24ì  ì˜ˆìƒ)\n",
        "essay_medium = \"\"\"\n",
        "The reading says bacteria is good for oil spill. But lecturer disagree.\n",
        "First reading say it is fast. But lecture say it is cold so it is slow. The bacteria need warm water to eat oil.\n",
        "Second, reading say it is safe. But lecture say no. Too many bacteria is bad for fish.\n",
        "So the plan is not good and we need to think about other ways.\n",
        "\"\"\"\n",
        "\n",
        "# Case 3: Low Score (20ì  ì´í•˜ ì˜ˆìƒ)\n",
        "essay_low = \"\"\"\n",
        "Oil spill is very bad. I think we need to clean it. Bacteria is small.\n",
        "I don't know if it works. Computers are good.\n",
        "\"\"\"\n",
        "\n",
        "# ==========================================\n",
        "# 3. ì±„ì  ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥\n",
        "# ==========================================\n",
        "if 'scorer' in locals():\n",
        "    print(\"\\n=== ğŸ“ TOEFL AI Scorer Demo ===\\n\")\n",
        "\n",
        "    s1 = predict_score(essay_high)\n",
        "    print(f\"[Case 1: High Quality Essay]\")\n",
        "    print(f\"â–¶ Predicted Score: {s1:.2f} / 30.00\\n\")\n",
        "\n",
        "    s2 = predict_score(essay_medium)\n",
        "    print(f\"[Case 2: Medium Quality Essay]\")\n",
        "    print(f\"â–¶ Predicted Score: {s2:.2f} / 30.00\\n\")\n",
        "\n",
        "    s3 = predict_score(essay_low)\n",
        "    print(f\"[Case 3: Low Quality Essay]\")\n",
        "    print(f\"â–¶ Predicted Score: {s3:.2f} / 30.00\\n\")"
      ]
    }
  ]
}