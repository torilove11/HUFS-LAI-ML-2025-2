# Assignment5. Model Training and Evaluation

## 0. Intro
### ν”„λ΅μ νΈ μ§„ν–‰ ν™κ²½
- λ΅μ»¬ ν™κ²½μ ν•λ“μ›¨μ–΄ ν•κ³„λ΅ μΈν•΄, λ¨λ“  λ¨λΈ μ‹¤ν— λ° ν•™μµμ€ colabμ—μ„ μ§„ν–‰λμ—μµλ‹λ‹¤.
- Colabμ—μ„ μ‹¤ν—μ΄ μ™„λ£λ ν›„, κ²°κ³Ό νμΌ(inference result, μµμΆ… ipynbνμΌ λ“±)λ§ λ΅μ»¬ ν™κ²½μΌλ΅ λ‹¤μ΄λ΅λ“ν• λ’¤ gitμ— pushν•λ” λ°©μ‹μΌλ΅ κ΄€λ¦¬ν–μµλ‹λ‹¤.

### μ¬ν„μ„± λ° inference.ipynb κµ¬μ„±
- λ¨λΈ μ¬ν„μ„±: μµμΆ… λ¨λΈ κ°€μ¤‘μΉλ” Hugging Faceμ κ³µκ° μ €μ¥μ†μΈ *jsjang0104/book-genre-classifier-bert*μ— λ΅λ“ν•μ€μµλ‹λ‹¤.
- μ‹¤μ  ν”„λ΅μ νΈ λ°©μ‹ vs. μ±„μ  νΈμ:
    - μ‹¤μ  ν”„λ΅μ νΈ λ°©μ‹: 
        - inference data μ ‘κ·Ό λ° result μ €μ¥μ„ μ„ν•μ—¬ μ „μ²΄ λ¦¬ν¬μ§€ν† λ¦¬λ¥Ό cloneν•λ” κ³Όμ •μ΄ cellμ— κµ¬ν„λμ–΄μμµλ‹λ‹¤.
        - colab ν™κ²½μ—μ„ μ§„ν–‰ν•μ—¬μ„ Hugging Face λ΅κ·ΈμΈ κ³Όμ • cellλ„ κµ¬ν„ν•μ€μµλ‹λ‹¤.
    - **π’΅μ±„μ  νΈμπ’΅**: 
        - μ¶”λ΅  λ°μ΄ν„° μƒν”μ„ μ½”λ“ λ‚΄λ¶€μ— ν•λ“μ½”λ”©ν•λ” μ…€μ„ λ³„λ„λ΅ μ¶”κ°€ν•μ—¬, repository λ³µμ  μ—†μ΄λ„ μ¦‰μ‹ μ¶”λ΅  κ²°κ³Όλ¥Ό ν™•μΈν•  μ μλ„λ΅ κµ¬μ„±ν•μ€μµλ‹λ‹¤.
        - λ΅μ»¬ ν™κ²½μ„ κ³ λ ¤ν•μ—¬ Hugging Face λ΅κ·ΈμΈ κ³Όμ • cellμ΄ λ³„λ„λ΅ λ¶„λ¦¬λμ–΄ μμµλ‹λ‹¤
- μ½”λ“ μƒμ„± λ° κ²°κ³Ό ν•΄μ„μ— μμ–΄ Geminiμ λ„μ›€μ„ λ°›μ•μµλ‹λ‹¤.

### νμΌ κµ¬μ΅° μ„¤λ…
submissions/202400420/assignment5/  
β”β”€β”€ datas/  
|   β”β”€β”€ eval_data.csv                   # evaluation dataset (assignment4 μμ§‘ λ°μ΄ν„° λ¶„ν• )  
|   β”β”€β”€ inference_data.csv              # inference dataset (μ‹¤μ  λ„μ„κ΄€ λ„μ„, νΈμλ¥Ό μ„ν•΄ κ³¨λ“λΌλ²¨μ„ ν¬ν•¨ν•κ³  μμ. (μ½”λ“ λ‚΄λ¶€μ—μ„λ” 'title' columnλ§ μ‚¬μ©ν•΄μ„ μν–¥ μ—†μ))  
|   β”β”€β”€ inference_result.csv            # inference κ²°κ³Ό (inference.ipynb μ½”λ“μ—μ„ μ €μ¥)   
|   β”β”€β”€ nomalized_confusion_matrix.png  # confusion matrix μ΄λ―Έμ§€   
|   β”β”€β”€ test_data.csv                   # test dataset (assignment4 μμ§‘ λ°μ΄ν„° λ¶„ν• )  
|   β””β”€β”€ train_data.csv                  # train dataset (assignment4 μμ§‘ λ°μ΄ν„° λ¶„ν• )  
β”β”€β”€ evaluation.ipynb                    # λ¨λΈ ν‰κ°€ μ½”λ“  
β”β”€β”€ inference.ipynb                     # λ¨λΈ μ¶”λ΅  μ½”λ“ (μμ‹κ°’ ν¬ν•¨)  
β”β”€β”€ README.md                           # ν”„λ΅μ νΈ μ”μ•½ λ° κ²°κ³Ό  
β””β”€β”€ training.ipynb                      # λ¨λΈ ν•™μµ μ½”λ“  

## 1. λ¨λΈ μ•„ν‚¤ν…μ²
- κΈ°λ° λ¨λΈ: mBERT 
    - mBERTλ” 104κ° μ–Έμ–΄λ΅ pre-trainingλ λ¨λΈλ΅, ν”„λ΅μ νΈμ—μ„ λ‹¤λ£¨κ³  μλ” λ‹¤κµ­μ–΄(λ…μΌμ–΄, μμ–΄, ν•κµ­μ–΄, λΌν‹΄μ–΄ λ“±) λ„μ„ λ°μ΄ν„°λ¥Ό μ²λ¦¬ν•λ” λ° μ ν•©ν•¨.
- νμΈνλ‹ λ°©μ‹: Task-specific Fine-tuning
    - Hugging Faceμ AutoModelForSequenceClassificationμ„ μ‚¬μ©ν•μ—¬ mBERTμ pre-trained weightsλ¥Ό λ³΄μ΅΄
    - ν”„λ΅μ νΈκ°€ μ§€ν–¥ν•λ” μ‘μ—…μΈ Classificationμ— λ§κ² λ§μ§€λ§‰ Classification Headλ§ λ°μ΄ν„°μ— λ§κ² fine-tuning μ§„ν–‰
- Classifier Layer κµ¬μ΅°: Pooling Layer (token vector μ¶”μ¶ / 768 features) -> Dropout (overfitting λ°©μ§€ / 768 features) -> Linear Layer (μµμΆ… 4κ° classλ΅ λ§¤ν•‘) 

## 2. λ°μ΄ν„°μ…‹ λ° μ „μ²λ¦¬
- λ°μ΄ν„° λ¶„ν•  λΉ„μ¨ (κ° λ°μ΄ν„° setλ³„ class λ¶„ν¬ μ μ‚¬λ„ ν™•μΈ μ™„λ£(training.ipynb μ½”λ“μ— λ…μ‹))
    - train set: 80% (model training)
    - validation set: 10% (training μ¤‘ μ„±λ¥ μ κ²€ λ° early stopping νλ‹¨)
    - test set: 10% (μµμΆ… μ„±λ¥ ν‰κ°€)
- ν΄λμ¤ λ¶κ· ν• μ²λ¦¬
    - κΈ°μ΅΄ λ°μ΄ν„°μ ν΄λμ¤ λ¶„ν¬κ°€ λ¶κ· ν•ν–μ (μ—­μ‚¬ 33.24%, λ¬Έν•™31.51%, μ‚¬νκ³Όν•™26.95%, **μ–΄ν•™8.29%**)
    - λ³΄μ™„μ„ μ„ν•΄ ν•™μµ μ‹ Minority ClassμΈ μ–΄ν•™μ μ¤‘μ”λ„λ¥Ό λ†’μ—¬ Weighted Loss Function μ μ© (νΉμ • class bias λ°©μ§€)
    - λ°©μ‹: κ° ν΄λμ¤μ λΉλ„μμ— λ°λΉ„λ΅€ν•λ” κ°€μ¤‘μΉ($W_i$)λ¥Ό κ³„μ‚°ν•μ—¬ CrossEntropyLoss(PyTorch) ν•¨μμ— μ μ©
    - κ°€μ¤‘μΉ κ³µμ‹: $W_i = 1 / (\text{λΉλ„μ}_i)$ (μ •κ·ν™” ν›„ μ‚¬μ©)



## 3. ν‰κ°€ μ§€ν‘ λ° μ„±λ¥ κ²°κ³Ό:

### 1. training.ipynb ν•™μµ κ²½κ³Ό λ¶„μ„
![Loss Accuracy_Curve](submissions/202400420/assignment5/datas/loss_accuracy.png)

1. Loss
- Train Loss
    - 3 Epoch λ™μ• 0.8993 -> 0.7356 -> 0.6499λ΅ κΎΈμ¤€ν κ°μ†ν•¨
    - λ¨λΈμ΄ training dataμ ν¨ν„΄μ„ μ•μ •μ μΌλ΅ ν•™μµν•μ€μμ„ μ‹μ‚¬
- Validation Loss
    - 3 Epoch λ™μ• 0.8457 -> 0.8676 -> 0.8276μΌλ΅ 2 Epochμ—μ„ μƒμΉν•λ©° κ³Όμ ν•© μ„ν—μ„ λ³΄μ€μΌλ‚ Epoch 3μ—μ„ λ‹¤μ‹ ν•λ½ν•μ—¬ μλ ΄ν•¨
    - μƒμΉ μ •λ„κ°€ ν¬μ§€ μ•μ€ μ μΌλ΅ λ―Έλ£¨μ–΄λ³΄μ•„ μΌμ‹μ μΌλ΅ λ¶μ•μ •μ„±μ„ λ„μ› μΌλ‚ μµμΆ…μ μΌλ΅λ” μΌλ°ν™” μ„±λ¥μ„ ν™•λ³΄ν• κ²ƒμΌλ΅ λ³΄μ„

2. Accuracy
- Train Accuracy
    - 3 Epoch λ™μ• 0.6417 -> 0.7259 -> 0.7655 λ΅ κΎΈμ¤€ν μ¦κ°€ν•¨
- Validation Accuracy
    - 3 Epoch λ™μ• 0.6937 -> 0.6751 -> 0.7199λ΅, Lossμ™€ λ§μ°¬κ°€μ§€λ΅ Epoch 2μ—μ„ μΌμ‹μ μΈ λ¶μ•μ •μ„±μ„ λ³΄μ€μΌλ‚, Epoch 3μ—μ„ λ‹¤μ‹ λ°λ“±ν•λ©° μµκ³  μ„±λ¥μ„ κΈ°λ΅ν•¨

3. Epoch μ„ μ • κ·Όκ±°
- μ°Έκ³  λ¬Έν— κ¶μ¥κ°’ μ¤€μ: BERTμ μ›λ…Όλ¬Έ(Devlin et al., 2018) λ° μΌλ°μ μΈ NLP νμΈνλ‹ κ°€μ΄λ“λΌμΈμ— λ”°λΌ, κ¶μ¥ Epoch μμΈ 3~4νλ¥Ό κΈ°μ¤€μΌλ΅ μ΄κΈ° ν•™μµ μ‹μ‘
- 3 Epoch μ‹ν–‰μ—μ„ Validation Lossκ°€ μλ ΄ν•κ³  Accuracyκ°€ μ μ • μμ¤€μ— λ„λ‹¬ν• μ , colab ν™κ²½μ μ ν•λ μ»΄ν“¨ν… λ¦¬μ†μ¤ λ“±μ„ κ³ λ ¤ν•μ—¬ ν¨μ¨μ μΈ ν•™μµμ„ μ§„ν–‰ν•κ³ μ μ¶”κ°€ ν•™μµ μ—†μ΄ training epoch 3μ—μ„ ν•™μµ μΆ…λ£

### 2. evaluation.ipynb κΈ°λ° μ„±λ¥ λ¶„μ„

**ν‰κ°€ μ§€ν‘ μ •μ**
1. Accuracy (μ •ν™•λ„)
  - μ „μ²΄ μμΈ΅ μ¤‘ μ •ν™•ν•κ² λ¶„λ¥λ λΉ„μ¨
  - $(TP+TN) / (TP+TN+FP+FN)$
  - λ¨λΈμ μ „λ°μ μΈ μ„±λ¥μ„ λ‚νƒ€λƒ„

2. Weighted Precision (μ •λ°€λ„)
  - λ¨λΈμ΄ PositiveλΌκ³  μμΈ΅ν• κ²ƒ μ¤‘ μ‹¤μ  PositiveμΈ λΉ„μ¨
  - $TP / (TP+FP)$
  - FPλ¥Ό μ¤„μ΄λ” κ²ƒμ΄ μ¤‘μ”ν•  λ•
  - 'μ–΄ν•™'μ—μ„ ν΄λμ¤ λ¶κ· ν•μ΄ κ΄€μ°°λμ–΄ κ°€μ¤‘ ν‰κ·  μ‚¬μ©

3. Weighted Recall (μ¬ν„μ¨)
  - μ‹¤μ  PositiveμΈ κ²ƒ μ¤‘ λ¨λΈμ΄ Positiveλ΅ μ •ν™•ν•κ² μμΈ΅ν• λΉ„μ¨
  - $TP / (TP+FN)$
  - False Negative (λ†“μΉλ” κ²ƒ)λ¥Ό μ¤„μ΄λ” κ²ƒμ΄ μ¤‘μ”ν•  λ•
  - 'μ–΄ν•™'μ—μ„ ν΄λμ¤ λ¶κ· ν•μ΄ κ΄€μ°°λμ–΄ κ°€μ¤‘ ν‰κ·  μ‚¬μ©

4. Weighted F1-score
  - Precisionκ³Ό Recallμ μ΅°ν™” ν‰κ· .
  - $2 \cdot (Precision \cdot Recall) / (Precision + Recall)$
  - Precisionκ³Ό Recallμ κ· ν•μ„ λ‚νƒ€λ‚΄λ” λ‹¨μΌ μ§€ν‘
  - 'μ–΄ν•™'μ—μ„ ν΄λμ¤ λ¶κ· ν•μ΄ κ΄€μ°°λμ–΄ κ°€μ¤‘ ν‰κ·  μ‚¬μ©

5. Macro F1-score
  - κ° ν΄λμ¤λ³„ F1-Scoreλ¥Ό κ³„μ‚° ν›„, ν΄λμ¤ ν¬κΈ°μ— μƒκ΄€μ—†μ΄ λ‹¨μ ν‰κ· 
  - μƒν” μκ°€ μ μ€ Minority Class(μ–΄ν•™)μ μ„±λ¥μ΄ λ¨λΈμ μµμΆ… μ§€ν‘μ— λ―ΈμΉλ” μν–¥μ„ ν™•λ€

**μµμΆ… μ„±λ¥ ν‘**  
| Metric | Average Type | Score |
| :--- | :--- | :--- |
| Accuracy | Overall | 0.7291 |
| F1-Score | Weighted | 0.7284 |
| F1-Score | Macro | 0.7262 |
| Precision | Weighted | 0.7314 |
| Recall | Weighted | 0.7291 |


**ν΄λμ¤λ³„ F1-Score**
- μ—­μ‚¬ (Geschichte): 0.6868
- λ¬Έν•™ (Literatur): 0.7348
- μ‚¬νκ³Όν•™ (Sozialwissenschaften): 0.7800
- μ–΄ν•™ (Sprachwissenschaft): 0.7032
  

**Confusion Matrix**
<img width="778" height="680" alt="normalized_confusion_matrix" src="https://github.com/user-attachments/assets/65454548-bcc9-4318-a9b3-f5a81a090469" />

- λ€κ°μ„  κ°’ = **Recall**
- λ€κ°μ„ μ΄ μ•„λ‹ κ°’ = μ¤λ¶„λ¥ λΉ„μ¨ (Prediced Label / Actual Label)
- ν•΄μ„
    - μ‚¬νκ³Όν•™ (Sozialwissenschaften) κ°•μ„Έ: μ‚¬νκ³Όν•™ ν΄λμ¤λ” μ£Όμ μ κ²½κ³„κ°€ λ…ν™•ν•μ—¬ κ°€μ¥ λ†’μ€ μ„±λ¥(0.77)μ„ λ³΄μ„.
        - λ¬Έν•™, μ–΄ν•™, μ—­μ‚¬μ μΈλ¬Έν•™ κ³„μ—΄μ—μ„λ” μ λ©μ—μ„ λ¨νΈν•¨μ΄ λ‹¤μ† μ΅΄μ¬ν•λ‚ 
        - μ‚¬νκ³Όν•™ κ³„μ—΄μ—μ„λ” μ λ©μ— μ‚¬μ©λλ” ν‚¤μ›λ“(κ²½μ , μ •μ±…, λ²• λ“±)κ°€ λ…ν™•ν•μ—¬ μ„±λ¥μ΄ μΆ‹κ² λ‚νƒ€λ‚ κ²ƒμΌλ΅ μ¶”μ •
    - μ–΄ν•™ (Sprachwissenschaft) μ•½μ„Έ: μ–΄ν•™ ν΄λμ¤λ” Recallμ΄ 0.65λ΅ κ°€μ¥ λ‚®μ. 
        - νΉν λ¬Έν•™(Literatur, 0.19)μ΄λ‚ μ—­μ‚¬(Geschichte, 0.11)λ΅ μ¤λ¶„λ¥λλ” κ²½ν–¥μ΄ νΌ
        - κ°€μ¤‘μΉ μ μ©μ—λ„ λ¶κµ¬, λ°μ΄ν„° μ–‘μ ν•κ³„λ΅ μ¶”μ •
    - μ£Όμ” μ¤λ¶„λ¥: μ „μ²΄ μ—­μ‚¬ classμ 21%κ°€ λ¬Έν•™μΌλ΅ μ¤λ¶„λ¥ λ¨
        - μΈλ¬Έν•™ κ³„μ—΄ λ‚΄μ—μ„ κ³ μ „, μ‹ ν™”, νΉμ • μ‹λ€ μ—°κµ¬ λ“± μ£Όμ κ°€ κ²ΉμΉλ©΄μ„ λ°μƒν•λ” νΌλ™μΌλ΅ μ¶”μ •

### 3. inference.ipynbμ—μ„μ κ²°κ³Ό κΈ°λ° μ„±λ¥ λ¶„μ„
- inference κ³Όμ •μ€ μ‹¤μ  μ¤μ¤νΈλ¦¬μ•„ λ„μ„κ΄€μ λ„μ„ λ°μ΄ν„° μ λ©μ„ μ‚¬μ©ν•μ—¬ λ¨λΈμ μ‹¤μ©μ„±μ„ ν™•μΈν•¨
- evaluation κ³Όμ •μ—μ„λ” confidenceκ°€ 70% μ΄ν•μΌ λ•λ§ ν΄λμ¤λ³„ confidenceλ¥Ό μ¶λ ¥ν–μ§€λ§, μ‹¤μ  μ‚¬μ©μ— μμ–΄μ„λ” μ¶λ ¥λ confidence λ©λ΅μ„ λ³΄κ³  **μ‚¬λμ΄ μ§μ ‘ μ„ νƒ**ν•  μ μκ²λ” λ¨λ“  dataμ— μ μ©ν•¨
- sample data: inference_data.csv
    - μ–΄ν•™, λ¬Έν•™, μ‚¬νκ³Όν•™, μ—­μ‚¬ κ° class λ³„λ΅ 5κ¶
    - λ…μΌμ–΄ 12κ¶, μμ–΄ 2κ¶, ν•κµ­μ–΄ 5κ¶, λΌν‹΄μ–΄ 1κ¶
- κ° ν΄λμ¤ λ³„ Accuracy:
    - μ–΄ν•™ (4/5)
    - λ¬Έν•™ (5/5)
    - μ‚¬νκ³Όν•™ (5/5)
    - μ—­μ‚¬ (1/5)
- μ¤λ¶„λ¥ μΌ€μ΄μ¤:
    - ABC der schwachen Verben (μ–΄ν•™μ„ λ¬Έν•™μΌλ΅ λ¶„λ¥ / confidence 0.8378)
        - λ¬Έλ²• κµμ¬μ„μ—λ„ 'ABC'λ‚ 'Verben'μ΄λΌλ” λ‹¨μ–΄κ°€ ν•™μµ κ³Όμ •μ—μ„ λ¬Έν•™ ν•™μµ μλ£μ™€ κ²Ήμ³ ν•΄μ„λμ–΄ λ°μƒν• κ²ƒμΌλ΅ μ¶”μ •
    - Lexikon der antiken Mythen und Gestalten (μ—­μ‚¬λ¥Ό λ¬Έν•™μΌλ΅ λ¶„λ¥ / confidence 0.3900)
        - κ³ λ€ μ‹ ν™” κ΄€λ ¨ μ λ©μ΄ λ¬Έν•™/μ—­μ‚¬/μ‚¬νκ³Όν•™ κ²½κ³„μ— κ±Έμ³ μμ–΄ λ¨λΈμ΄ κ°€μ¥ λ‚®μ€ confidence(0.39)λ΅ μμΈ΅ν•λ©° μ‹¤ν¨
    - BIBLIOTHEK DER GESCHICHTE UND POLITIK DIE FRAN... (μ—­μ‚¬λ¥Ό λ¬Έν•™μΌλ΅ λ¶„λ¥ / confidence 0.5551)
        - 'GESCHICHTE(μ—­μ‚¬)'κ°€ λ…μ‹λμ–΄ μμμ—λ„ λ¬Έν•™μΌλ΅ μ¤λ¶„λ¥. 
        - 'BIBLIOTHEK (μ΄μ„)'κ°€ 'λ¬Έν•™ μ΄μ„'μ μ λ© ν¨ν„΄κ³Ό μ μ‚¬ν•κ² μΈμ‹λμ—κ±°λ‚, 'μ •μΉ'λΌλ” ν‚¤μ›λ“κ°€ μ‚¬νκ³Όν•™ κ³„μ—΄κ³Ό μΈμ ‘ν•κ² ν•΄μ„λλ©΄μ„ λ¨λΈμ΄ λ¨νΈν•¨(0.5551)μ— λΉ μ§„ κ²ƒμΌλ΅ μ¶”μ •
    - μ„μ–‘λ―Έμ μ‚¬ (μ—­μ‚¬λ¥Ό λ¬Έν•™μΌλ΅ λ¶„λ¥ / confidence 0.7993)
        - 'λ―Έμ μ‚¬'λ” μ—­μ‚¬ ν‚¤μ›λ“μ΄λ‚, 'λ―Έμ 'μ΄λΌλ” μ£Όμ κ°€ μΈλ¬Έν•™ λ‚΄μ—μ„ λ¬Έν•™κ³Ό μΈμ ‘ν• μμ  μμ—­μΌλ΅ λ¶„λ¥λλ” κ²½ν–¥μ΄ μμ–΄ λ¨λΈμ΄ λ‘ ν΄λμ¤ κ°„μ κ²½κ³„λ¥Ό νΌλ™ν• κ²ƒμΌλ΅ μ¶”μ •
    - ν•κµ­μ™Έκµ­μ–΄λ€ν•™κµ 60λ…„μ‚¬ I. μ‹λ€λ³„ μ™Έλ€μ‚¬ (μ—­μ‚¬λ¥Ό μ–΄ν•™μΌλ΅ λ¶„λ¥ / confidence 0.9820)
        - '70λ…„μ‚¬'λ” μ—­μ‚¬ ν‚¤μ›λ“μ΄λ‚, λ¨λΈμ΄ 'μ™Έκµ­μ–΄'ν‚¤μ›λ“λ¥Ό λ” μ§‘μ¤‘ν•μ—¬ μ–΄ν•™μΌλ΅ λ¶„λ¥ν• κ²ƒμΌλ΅ μ¶”μ •


## 4. λ¨λΈ κ°€μ¤‘μΉ μ €μ¥ μ„μΉ
- μµμΆ… νμΈνλ‹λ λ¨λΈ κ°€μ¤‘μΉ: Hugging Faceλ¥Ό ν†µν•΄ μ¬ν„ κ°€λ¥ 
- κ³µκ° μ €μ¥μ†μ— μ—…λ΅λ“ (λ³„λ„μ μΈμ¦ μ—†μ΄ λ‹¤μ΄λ΅λ“ κ°€λ¥)
- Hugging Face Link: jsjang0104/book-genre-classifier-bert

## 5. νΉμ΄μ‚¬ν•­ λ° ν•κ³„
- λ‹¤κµ­μ–΄ μ²λ¦¬μ μ–΄λ ¤μ›€
    - λ„λ©”μΈ-μ–Έμ–΄ λ¶μΌμΉ: input sequenceλ” λ…μΌμ–΄, μμ–΄, ν•κµ­μ–΄, λΌν‹΄μ–΄ λ“±μ΄ μ„μ—¬ μμμΌλ‚ output sequenceλ” λ…μΌμ–΄ κ³ μ • (mBERT μ‚¬μ©μ—λ„ λ¶κµ¬ν•κ³  νƒ€ μ–Έμ–΄λ΅μ λ§¤ν•‘ κ³Όμ •μ—μ„ νΌλ€ λ°μƒ)
    - μμ‹: 'ν•κµ­μ™Έκµ­μ–΄λ€ν•™κµ 70λ…„μ‚¬'λ” '70λ…„μ‚¬'μ—μ„ 'μ—­μ‚¬'μ μλ―Έλ¥Ό μ§€λ‹μ§€λ§, mBERTκ°€ 'μ™Έκµ­μ–΄'λ¥Ό 'μ–΄ν•™'μ™€ κ°•ν•κ² μ—°κ²°μ‹μΌ μ¤λ¶„λ¥

- μ–΄ν•™ (Sprachwissenschaft) ν΄λμ¤μ Recall μ €μ΅°: 
    - Weighted Lossλ¥Ό μ‚¬μ©ν–μμ—λ„ λ¶κµ¬ν•κ³ , minority classμΈ μ–΄ν•™ κ΄€λ ¨ λ„μ„κ°€ λ¬Έν•™ λλ” μ—­μ‚¬λ΅ μλ» μμΈ΅λλ” κ²½μ°κ°€ λ§μ•μ
    - μ΄λ” μ–΄ν•™ μλ£κ°€ λ¬Έν•™ μ‘ν’ ν•΄μ„¤μ΄λ‚ μ–Έμ–΄ λ³€μ²μ‚¬ μ—°κµ¬ λ“± λ‹¤λ¥Έ μΈλ¬Έν•™ λ¶„μ•Όμ™€ μ λ© ν‚¤μ›λ“λ¥Ό κ³µμ ν•λ” κ²½μ°κ°€ λ§μμΌλ΅ μ¶”μ •
    
- ν–¥ν›„ κ°μ„  λ°©ν–¥
    - λ°μ΄ν„° μ¦κ°•: μ–΄ν•™ ν΄λμ¤μ— λ€ν• μ¶”κ°€ λ°μ΄ν„°λ¥Ό μμ§‘ν•μ—¬ λ¨λΈμ λ¶κ· ν• λ¬Έμ  ν•΄μ†
    - λ” κΉμ€ λ¨λΈ: mBERTλ³΄λ‹¤ λ„λ©”μΈ μ§€μ‹μ„ λ” μ μ΄ν•΄ν•λ” German BERTλ“±μ λ¨λΈμ„ μ‚¬μ©ν•κ³ , λ…μΌμ–΄ μ™Έ μ–Έμ–΄λ” λ²μ—­ ν›„ μ²λ¦¬ν•λ” λ°©μ‹ κ³ λ ¤ κ°€λ¥
