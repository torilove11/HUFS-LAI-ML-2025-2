# Assignment 4: Data Collection and Analysis

## 파일 구조 설명
```
assignment4/
├─ data/
│  ├─ dataset_for_labeling.csv      # 전체 데이터에 라벨링한 것(2077개)
│  ├─ dataset_manual_cleaned.csv    # (전처리 이전 최종 데이터) dataset_for_label링에서 반복적인 데이터 제거 데이터(1355개)
│  ├─ hufs_main.csv                 # 학교 메인 홈페이지 공지, 학사, 장학을 크롤링한 데이터 원본
│  ├─ iel_notice.csv                # 국제통상학과 notice, 자유게시판을 크롤링한 데이터 원본
│  ├─ lai_notice.csv                # Language & AI 융합학부 공지, 학부소식을 크롤링한 데이터 원본
│  ├─ test.csv                      # dataset_manual_cleaned에서 라벨링, 제목, 본문만 남긴 assignment5에서 사용할 파일들
│  ├─ train.csv
│  └─ val.csv
├─ crawl_iel.py                    # 국제통상학과 홈페이지 크롤링 코드
├─ crawl_lai.py                    # Language & AI 융합학부 크롤링 코드
├─ crawl_main.py                   # 학교 홈페이지 크롤링 코드
├─ data_analysis.ipynb             # 데이터 분석 결과
├─ prepare_dataset.py              # 크롤링한 공지사항 중 중복을 제거해서 dataset_for_labeling 생성
├─ process_dataset.py              # dataset_manual_cleaned에서 라벨링, 제목, 본문만 남겨 test, train, val 파일 생성
└─ README.md
```

## 데이터 수집 및 전처리

### 데이터 수집 과정
- 학교, 국제통상학과, Language & AI 융합학부 홈페이지를 크롤링했다 (11월 22일 오후 기준)
  - 학교 메인 홈페이지 공지, 학사, 장학: 각각 52페이지씩 크롤링
  - 국제통상학과, Language & AI 융합학부: 모든 공지를 크롤링
- 각 홈페이지는 `crawl_iel.py`, `crawl_lai.py`, `crawl_main.py` 코드로 크롤링하여 `hufs_main.csv`, `iel_notice.csv`, `lai_notice.csv`에 저장했다.
- 크롤링한 내용은 제목, 본문, 날짜, 링크, 카테고리(예시. 공지, 학사 등)으로 구분해 두었다.
- 이렇게 수집한 데이터 중 `prepare_dataset.py`로 동일한 제목과 게시 날짜를 가지고 있는 것은 중복으로 간주하여 제거한 후 전체 공지를 합쳐 `dataset_for_labeling.csv`에 저장했다.
  - 카테고리가 달라도 중복되는 경우가 있고, 고정된 공지 사항은 크롤링 한 페이지가 넘어갈 때마다 반복적으로 크롤링 되어서이다.

### 라벨링 및 주기적인 공지 제거
- 나와의 관련도는 1 또는 0, 중요도는 2, 1, 0으로 구분했다.
- 기준:
  - 관련도: 내가 대상이 아니거나(예. 글로벌캠퍼스 공지), 대상이어도 알림 받을 필요가 없는 것들(예. 참여할 일 없는 외국어 특강)은 0, 나머지 어떤 형태라도 알림을 받을 가능성이 있는 것은 1로 처리했다.
  - 중요도: 놓치면 안되는 중요한 것들(예. 수강신청, 일부 장학금)은 2, 즉시 알림을 받아야 하는 것은 아니지만 알려주면 좋을 것들(예. 관심 있는 특강, 이클래스 중지)은 1, 그 외 나와 관련은 있지만 중요한 알림까지는 없는 것들(예. 관심분야가 아닌 특강)은 0으로 표기했다.
- 이렇게 `dataset_for_labeling.csv`의 모든 데이터를 관련도와 중요도를 각각 라벨링한 후, 내용상 비슷한 내용이 주기적으로 반복되는 공지들은 오버피팅을 발생시킬 가능성이 있기에 수동으로 제거해 `dataset_manual_cleaned.csv`에 저장했다.
- 제거한 공지의 예시: 분기마다 반복되는 수강신청 관련 공지는 매년 반복적으로 학사 공지에 올라오기에 1학기, 2학기, 여름계절, 겨울계절을 한 개 씩만 남기고 제거, 반복되는 장학금 공지 한 개 빼고 제거 등 주기성이 있는 것들.
- 이렇게 수동 제거한 데이터를 `process_dataset.py`를 사용해 전처리하고 시계열 순으로 8:1:1비율로 분할해 `train.csv`, `val.csv`, `test.csv`를 만들었다.

### 추가 전처리
- 본문에서 년도, 전화번호, "안녕하세요. Language & AI 사무실입니다."를 제거했다.
  - 년도: 주기적으로 반복되는 공지를 제거하는 과정에서 대부분 2025년 공지가 남았는데 모델이 잘못해서 2025라는 년도 값이 중요할 것이라는 해석을 방지.
  - 전화번호: 전화번호로 캠퍼스나 공지한 기관을 구분해 주제별로 구분하지 못하는 상황을 방지.
  - "안녕하세요. Language & AI 사무실입니다.": 상대적으로 중요도 0이 아닌 내용들은 lai 데이터가 iel데이터보다 훨씬 많았기에 lai 공지에서 자주 등장하는 이 멘트만으로 모델이 중요도 1 또는 2로 처리하는 것을 방지.
  - 제목, 내용만 남기기: 학습은 제목, 내용, 라벨링만으로 진행할 예정이다. 원본 데이터에서 수집한 날짜, 링크 등은 Assignment6에서 실제 사용할 서비스에서는 필요하지만 학습 과정에서는 아니다.
  - 본문이 없는 공지의 경우, ' ' 처리로 null이 되지 않도록 했다.

## 데이터 분석 결과

### 주요 통계
- `dataset_for_labeling.csv`에서 중복을 제거한 원본 공지의 경우 2077개가 나왔다.
- 반복적인 공지를 제거한 `dataset_manual_cleaned.csv`는 1355개 공지가 남았고, 이중 본문 내용이 없는 데이터는 83개였다.
- 관련도: 관련도 0은 570개, 관련도 1은 785개로 상대적으로 개수가 비슷했다.
- 중요도: 중요도 0은 948개, 1은 284개, 2는 123개였다.
- 출처별 공지 개수: `dataset_manual_cleaned.csv`에서 학교 메인 홈페이지 공지는 437개, 학사 178개, 장학 305개, iel 202개, lai 233개이다.
- 공지사항 제목과 본문 길이의 합은 대부분 5000글자 이내였고 평균 길이는 968.3, 중간값은 663.0이었다. 가장 긴 공지는 약 17500글자 정도였다.

### 분석
- 관련도는 상대적으로 데이터 분포가 균형을 이루었다.
- 중요도는 0, 1, 2 사이의 데이터 편차가 심했다. 따라서 evaluation으로 Accuracy를 사용할 경우 실제보다 정확도가 높게 측정될 가능성이 있다. 우선 F1-Score를 주요 지표로 평가할 예정이다. 만일 모델의 성능이 잘 나오지 않는다면 가중치 조절 등의 방법을 이용할 것이다.
- 텍스트 평균 길이인 968자를 토큰으로 환산하면 BERT의 최대 처리 토큰 수인 512를 넘을 가능성이 있다. 우선 validation까지는 진행해 보고, 성능이 좋지 않다면 문서별 성향을 고려해 토큰을 자르는 방법 또는 sliding window 등의 방법을 고려해 봐야겠다.
- 본문이 없는 데이터가 83개 있었다. 이 경우 관련도는 제목만으로 알 수 있어 제목만으로 관련도 0, 1을 구분했다. 중요도의 경우 제목만 보고 완전히 중요하지 않을 것으로 판단되면 0, 조금이라도 중요할 가능성이 있으면(예. 장학 공지) 2로 라벨링했다. 만일 학습이 제대로 되지 않는다면 향후 Assignment6에서는 본문이 없는 데이터는 학습이 아닌 규칙성으로 처리해야 할 가능성도 있다.