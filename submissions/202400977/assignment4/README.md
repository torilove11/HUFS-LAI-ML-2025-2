# 뉴스 데이터셋 분석 및 품질 보고서 (EDA Report)

## 1. 개요 (Overview)

### 1.1 프로젝트 배경: 정보의 파편화 문제
인공지능(AI)을 전공하는 학생으로서, 최신 기술 트렌드를 파악하는 것은 필수적인 일과이다. 그러나 실제 기술 이슈는 단순히 'IT/Tech' 카테고리에만 머물러 있지 않다.

- **현황:** AI 기술이 사회 전반에 융합되면서, 중요한 기술 뉴스가 **'정치(Politics)', '경제(Economy)', '사회(Society)' 등 다양한 카테고리에 산재**되어 있다.
    
- **문제점:** 예를 들어, 정부의 AI 데이터 센터 구축 명령이나 반도체 보조금 정책 등은 전공자에게 매우 중요한 '기술 뉴스'임에도 불구하고, 기존 포털에서는 '정치'나 '경제' 뉴스로 분류되어 Tech 뉴스 피드에서 누락되는 경우가 발생한다.
### 1.2 해결 방안: `CS_Insight` 통합 카테고리 설계
본 프로젝트는 이러한 한계를 극복하기 위해, 뉴스 기사의 **원천 카테고리(Original Category)에 의존하지 않고, 텍스트의 맥락(Context)을 분석하여 컴퓨터 관련 정보를 하나로 묶는 `CS_Insight` 클래스**를 새롭게 정의하였다.

- **구체적 사례 (Case Study):**
    - **기사 제목:** "Trump Orders Construction of A.I. Platform to Use Troves of Government Data for Research"
    - **기존 분류:** `Politics` (정치 행위로 간주)
    - **본 프로젝트 분류:** **`CS_Insight`** (AI 연구 플랫폼 구축이라는 기술적 내용에 주목)
        
- **데이터 구축 전략:** 위와 같은 사례를 능동적으로 수집하기 위해, 특정 도메인(정치, 경제 등)에 구애받지 않고 **전공 관련 키워드(AI, Platform, Data 등)가 포함된 기사를 `CS_Insight`로 재레이블링(Re-labeling)** 하여 학습 데이터를 구축하였다.

### 1.3 모델 학습 목표
이를 통해 향후 개발될 머신러닝 모델이 **"정치면에서 나온 기사니까 정치 뉴스다"** 라는 단순한 편견을 버리고, **"정치면에 실렸더라도 내용이 AI 플랫폼에 관한 것이므로 전공자가 읽어야 할 뉴스다"** 라고 판단할 수 있는 **지능형 분류 능력**을 갖추게 하는 것이 최종 목표이다.

### 1.4 데이터 정보 (Data Info)
- **수집 출처:** NYT, BBC, Wired, The Verge, HuffPost 등 주요 언론사 RSS
- **수집 기간:** 2024년 11월 25일 (일일 수집 데이터 기준)
- **데이터 크기 (Shape):** 총 409 개 샘플 (행), 3개 컬럼 (열)
- **주요 칼럼 (Columns):**
    - `headline`: 기사 제목 (Feature, 문자열)
    - `original_category`: 언론사 원본 카테고리
    - `category`: 재정의된 학습용 라벨 (Target, 문자열)

## 2. 데이터 구조 및 기초 통계 확인 (Data Overview)

수집된 데이터셋의 기본 구조를 파악하고, 학습에 앞서 데이터의 결측 여부와 클래스 분포를 점검하였다.
### 2.1 데이터 샘플 확인 (`head()`)
상위 5개 샘플을 통해 데이터프레임의 구조를 확인한 결과, 다음과 같은 3개의 핵심 컬럼으로 구성되어 있음을 확인하였다.

- **headline:** 뉴스 기사의 제목 (모델의 입력 데이터, Feature).
- **original_category:** RSS 피드에서 제공한 원본 카테고리.
- **category:** 키워드 기반 재분류가 적용된 최종 레이블 (모델의 예측 타겟, Target).

### 2.2 데이터 무결성 검증 (`info()`)
`info()` 함수를 통해 데이터 타입과 결측치를 점검하였다.

- **결측치(Null):** 모든 컬럼에서 결측값이 **0개**(`Non-Null Count`가 전체 행 수와 동일)로 나타나, 별도의 결측치 대체(Imputation) 과정이 불필요함을 확인하였다.
- **데이터 타입(Dtype):** 텍스트 데이터인 `headline`과 범주형 데이터인 `category` 모두 `object` 타입으로 정상 인식되었다.

### 2.3 클래스 분포 확인 (`value_counts()`)
`category` 컬럼의 빈도수를 확인하여 클래스 간 불균형(Class Imbalance) 여부를 진단하였다.

- **분포 현황:**
    - 가장 데이터가 많은 클래스(Major): **`Society`** (116 개)
    - 가장 데이터가 적은 클래스(Minor): **`CS_Insight`** (57 개)
        
- **분석:** `CS_Insight` 카테고리는 특정 키워드 필터링을 통해 생성된 소수 클래스(Minority Class)이므로, 타 카테고리에 비해 데이터 수가 적게 나타났다. 

### 2.4 중복 데이터 (Duplicates) 점검
RSS 피드 특성상 시간차를 두고 동일한 기사가 중복 수집될 가능성이 있어, 이를 사전에 제거하지 않으면 모델 평가 시 **Train/Test 데이터 누수(Leakage)** 나 **과적합(Overfitting)** 을 유발할 수 있다.

- **검증 방법:** `duplicated(subset=['headline'])` 함수를 통해 기사 제목이 완벽히 동일한 샘플을 탐지하였다.
- **검증 결과:** 중복된 샘플 개수는 0 개로 확인되었다.
- **결론:** 데이터 수집 단계에서의 1차 전처리 로직이 정상 작동하였으며, 모든 데이터가 고유한(Unique) 정보를 담고 있음을 확인하였다.

## 3. 카테고리별 데이터 분포 시각화 (Class Distribution Analysis)

Target 변수인 `category`의 분포를 시각화하여, 학습 데이터가 특정 클래스에 편중되어 있는지 확인하였다. 이는 머신러닝 모델이 다수 클래스(Majority Class)로 편향(Bias)되는 것을 방지하기 위한 사전 분석 단계이다.

### 3.1 시각화 결과

- **불균형 존재:** 그래프 확인 결과, 위에서 설명했듯이 카테고리 간 데이터 개수의 차이가 관찰된다.
    
    - **최다 빈도 클래스 (Majority):** `Society` (약 116 개) - 일반적인 RSS 뉴스 공급량이 많음.
    - **최소 빈도 클래스 (Minority):** `CS_Insight` (약 57 개) - 특정 키워드로 필터링된 특화 카테고리임.

### 3.2 결과 해석 및 판단

처음에는 직접 정의한 `CS_Insight` 카테고리의 데이터가 부족하여 모델 학습에 어려움이 있지 않을까 우려했으나, 시각화 결과를 통해 다음과 같은 긍정적인 신호를 확인할 수 있었다.

1. **양호한 비율:** 가장 많은 `Society`와 가장 적은 `CS_Insight`의 비율이 약 **2:1** 정도로, 심각한 불균형은 발견되지 않았다.
2. **전반적인 분포의 균형:** 최대/최소 클래스뿐만 아니라, 중간에 위치한 `Economy`, `Technology`, `Politics` 카테고리들도 어느 한쪽에 치우치지 않고 적당히 균등한 분포를 보이고 있다.

특정 카테고리가 전체의 과반수를 차지하거나, 반대로 극소수만 존재하는 '쏠림 현상'이 없기 때문에, 이 데이터셋은 머신러닝 모델이 각 주제를 공정하게 학습하기에 아주 적합한 상태라고 판단된다.

## 4. 헤드라인 길이 분포 분석 (Text Length Analysis)

NLP 모델 학습 시 텍스트의 길이가 너무 들쑥날쑥하면 학습에 방해가 될 수 있다. 따라서 `char_length`(글자 수) 히스토그램을 통해 데이터의 분포가 안정적인지 확인해 보았다.

### 4.1 기초 통계 및 분포 형태

- **평균 길이:** 약 62.27 자
    
- **분포 형태:**
    - 시각화 결과, 데이터가 평균선(붉은 점선)을 중심으로 좌우 대칭을 이루는 **정규분포(Normal Distribution)** 와 유사한 형태를 띠고 있다.
        
    - 대부분의 헤드라인이 **40자에서 80자 사이**에 밀집되어 있어, 기사 제목의 호흡이 매우 일정하다는 것을 확인할 수 있다.
    

### 4.2 데이터 품질 진단

1. **이상치(Outlier) 점검:**
    
    - **짧은 텍스트:** 20자 미만의 데이터가 소수 관측되나, 빈도수가 매우 낮아 전체 학습에 영향을 줄 수준은 아닌 것으로 판단됩니다.
        
    - **긴 텍스트:** 100자를 초과하는 데이터 역시 거의 없어, 문단 수준의 긴 텍스트가 섞여 들어오는 오류(Noise)는 없는 것으로 확인했다.
        
2. **결론:**
    
    - 극단적으로 길거나 짧은 문장이 없기 때문에, 추후 모델링 단계에서 별도의 길이 제한(Truncation)이나 과도한 패딩(Padding) 처리를 고민하지 않아도 될 것으로 생각한다.


## 5. CS_Insight 카테고리 키워드 정합성 검증 (Keyword Validity Check)

앞서 정의한 `CS_Insight` 카테고리는 RSS 원본 데이터가 아닌, **'전공 관련 키워드 포함 여부'** 라는 독자적인 규칙(Rule-based)에 의해 생성되었다. 따라서 해당 카테고리로 분류된 기사들이 **실제로 기술(Tech) 및 CS 도메인과 관련이 있는지 검증**하는 과정이 필수적이다.

이를 위해 `CS_Insight` 데이터의 텍스트를 분석하여, 불용어(Stopwords)를 제외한 **상위 빈도 단어(Top 10 Keywords)** 를 시각화하였다.

### 5.1 분석 방법

1. **텍스트 정제:** 모든 헤드라인을 소문자로 변환하고, 정규표현식을 이용해 3글자 이상의 의미 있는 단어만 추출하였다.

2. **불용어 제거:** 'the', 'and', 'will' 등 문법적 기능만 하는 단어들을 제거하여 분석의 정확도를 높였다.

3. **빈도 분석:** `Counter` 객체를 사용하여 가장 많이 등장한 단어 상위 10개를 추출하였다.

### 5.2 시각화 결과 및 해석

- **주요 키워드:** 분석 결과 **`tech`**, **`data`**, **`google`** 과 같은 단어들이 상위권을 차지하였다.
    
- **정합성 확인:**
    
    - 추출된 단어들은 정치(Politics)나 일반 경제(Economy) 뉴스에서 주로 등장하는 단어(Election, Tax, Campaign 등)와 뚜렷하게 구분되는 **기술적 특성(Technical Specificity)** 을 보인다.
        
    - 이는 본 프로젝트에서 설계한 **'키워드 기반 재분류(Re-labeling) 알고리즘'이 의도한 대로 정확하게 작동**하여, 방대한 뉴스 데이터 속에서 CS 전공자에게 필요한 정보를 효과적으로 필터링했음을 시사한다.

### 5.3 결론

구축된 `CS_Insight` 데이터셋은 노이즈가 적고 도메인 적합성(Relevance)이 높아, 향후 진행될 **머신러닝 모델 학습(Classification Task)의 고품질 학습 데이터(Ground Truth)로 활용하기에 적합**하다는 결론을 도출하였다.


## 6. 카테고리별 단어 수 분포 비교 (Comparative Analysis of Word Counts)

헤드라인의 글자 수(Character)뿐만 아니라, **단어 수(Word Count)** 의 분포가 카테고리별로 유의미한 차이를 보이는지 Boxplot(상자 수염 그림)을 통해 분석하였다.

만약 특정 카테고리(예: Politics)의 기사 제목이 타 카테고리에 비해 현저히 길거나 짧다면, 머신러닝 모델이 텍스트의 '의미'가 아닌 **'길이'를 힌트(Shortcut)로 삼아 분류하는 편향(Bias)이 발생**할 수 있기 때문이다.

### 6.1 시각화 해석 기준

- **박스(Box):** 데이터의 중간 50%(IQR)가 모여 있는 구간.
- **가로선(Median):** 각 카테고리 헤드라인 단어 수의 중앙값.
- **점(Points):** 일반적인 범위를 벗어난 이상치(Outlier).

### 6.2 분석 결과

- **중앙값(Median)의 일치:**
    
    - 그래프를 확인한 결과, 5개 카테고리 모두 중앙값이 약 10~11 단어 부근에 거의 일직선으로 위치하고 있다.
    - 이는 분야에 상관없이 뉴스 헤드라인의 호흡(길이)이 매우 일정하다는 것을 보여준다.
    
- **분포 및 이상치:**
    
    - 전체적으로 모든 박스(Box)의 크기와 위치가 비슷하다.

### 6.3 결론

카테고리별로 텍스트 길이에 대한 극단적인 차이가 발견되지 않았다. 따라서 향후 구축할 모델은 텍스트의 '길이 정보'가 아닌, **'단어의 출현 패턴(TF-IDF 등)'과 '문맥(Context)'에 집중하여 공정한 학습을 수행**할 수 있을 것으로 기대된다.

## 7. 최종 결론 및 향후 계획 (Conclusion & Future Works)

본 과제(Assignment 4)를 통해 뉴스 데이터 수집부터 정제, 그리고 탐색적 데이터 분석(EDA)까지의 과정을 수행하였다. 분석 결과를 요약하고 이를 바탕으로 한 향후 모델링 계획을 정리하면 다음과 같다.

### 7.1 데이터 분석 요약 (Summary)

1. **데이터 무결성 확보:** 결측치(Null)와 중복 데이터가 **0건**임을 확인하였으며, 이상치(Outlier) 또한 발견되지 않아 별도의 복잡한 정제 과정 없이 즉시 학습에 투입 가능한 Dataset을 구축하였다.

2. **`CS_Insight` 가설 검증:** 독자적으로 설계한 키워드 필터링 로직이 실제 기술 관련 뉴스들을 정확하게 분류해냈음을 확인하였으며, 클래스 분포 또한 최대/최소 비율이 약 **2:1** 수준으로 학습하기에 안정적인 균형을 유지하고 있다.

3. **편향 요소 배제:** 카테고리별 텍스트 길이(Word Count)에 큰 차이가 없어, 모델이 텍스트의 길이가 아닌 **'실질적인 내용(Semantics)'** 을 학습할 수 있는 환경이 조성되었다.


### 7.2 한계점 및 개선 방안

- **데이터의 절대적 양:** 현재 확보된 약 400여 개의 데이터는 초기 학습(Baseline)용으로는 충분하나, 고성능 모델을 구축하기에는 다소 부족할 수 있다.

- **개선:** RSS 수집 스크립트를 주기적으로 실행하여 데이터를 누적(Accumulate)함으로써, 데이터 양 부족 문제를 점진적으로 해결할 예정이다.