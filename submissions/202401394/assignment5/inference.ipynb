{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gdown\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ==========================================================================\n",
        "# [ì„¤ì •] ë‘ ëª¨ë¸ì˜ Google Drive IDë¥¼ ê°ê° ì…ë ¥í•˜ì„¸ìš”!\n",
        "# ==========================================================================\n",
        "# 1. íŒ€í”Œ ë¶„ë¥˜ ëª¨ë¸ (Is_Teamplay) - ê¸°ì¡´ model.pt ID\n",
        "teamplay_file_id = '1hcl250N4eFpdCpxIZlJNLQAv5FJpUvRX'\n",
        "\n",
        "# 2. ê³¼ì œ ë¶€ë‹´ ëª¨ë¸ (Burden_Score) - ë°©ê¸ˆ ì—…ë¡œë“œí•œ burden_model.pt ID\n",
        "burden_file_id   = '1fCQ8Qr_GxJtcqAn7l91_Bf64GdDfRyyC'  # <--- ì—¬ê¸°ì— ìƒˆ ID ë¶™ì—¬ë„£ê¸°\n",
        "\n",
        "# ==========================================================================\n",
        "\n",
        "# íŒŒì¼ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜\n",
        "def download_file(file_id, filename):\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    if os.path.exists(filename):\n",
        "        os.remove(filename) # ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œ\n",
        "    print(f\"ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ ì¤‘... (ID: {file_id})\")\n",
        "    gdown.download(url, filename, quiet=False)\n",
        "\n",
        "# ë‘ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰\n",
        "download_file(teamplay_file_id, 'model.pt')\n",
        "download_file(burden_file_id, 'burden_model.pt')\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ (ë¶„ë¥˜ìš© vs íšŒê·€ìš© êµ¬ë¶„)\n",
        "# --------------------------------------------------------------------------\n",
        "MODEL_NAME = \"monologg/distilkobert\"\n",
        "MAX_LEN = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_models():\n",
        "    print(\"\\nâ³ ëª¨ë¸ 2ê°œ ë¡œë”© ì¤‘...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "    # 1. íŒ€í”Œ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ\n",
        "    model_cls = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2, trust_remote_code=True)\n",
        "    try:\n",
        "        model_cls.load_state_dict(torch.load('model.pt', map_location=device, weights_only=False))\n",
        "    except:\n",
        "        model_cls.load_state_dict(torch.load('model.pt', map_location=device))\n",
        "    model_cls.to(device).eval()\n",
        "\n",
        "    # 2. ê³¼ì œ ë¶€ë‹´(íšŒê·€) ëª¨ë¸ ë¡œë“œ (num_labels=1)\n",
        "    model_reg = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1, trust_remote_code=True)\n",
        "    try:\n",
        "        model_reg.load_state_dict(torch.load('burden_model.pt', map_location=device, weights_only=False))\n",
        "    except:\n",
        "        model_reg.load_state_dict(torch.load('burden_model.pt', map_location=device))\n",
        "    model_reg.to(device).eval()\n",
        "\n",
        "    print(\"âœ… ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
        "    return tokenizer, model_cls, model_reg\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# í†µí•© ì¶”ë¡  í•¨ìˆ˜\n",
        "# --------------------------------------------------------------------------\n",
        "def analyze_syllabus(tokenizer, model_cls, model_reg, text):\n",
        "    inputs = tokenizer(\n",
        "        text, return_tensors='pt', max_length=MAX_LEN, truncation=True, padding='max_length'\n",
        "    )\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 1. íŒ€í”Œ ì˜ˆì¸¡\n",
        "        out_cls = model_cls(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        probs = F.softmax(out_cls.logits, dim=1)\n",
        "        prob_team = probs[0][1].item() * 100\n",
        "        is_teamplay = torch.argmax(out_cls.logits, dim=1).item()\n",
        "\n",
        "        # 2. ê³¼ì œ ë¶€ë‹´ ì˜ˆì¸¡ (0.0 ~ 1.0 -> 0 ~ 100ì ìœ¼ë¡œ ë³€í™˜)\n",
        "        out_reg = model_reg(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        burden_score = out_reg.logits.item() * 100\n",
        "\n",
        "    return is_teamplay, prob_team, burden_score\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\n",
        "# --------------------------------------------------------------------------\n",
        "try:\n",
        "    if os.path.exists('model.pt') and os.path.exists('burden_model.pt'):\n",
        "        tokenizer, model_cls, model_reg = load_models()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸ“ HAT-N ìµœì¢… ë¶„ì„ (íŒ€í”Œ ìœ ë¬´ & ê³¼ì œ ë¶€ë‹´ ì˜ˆì¸¡)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # [Scenario 1] íŒ€í”Œ O, ê³¼ì œ ë§ìŒ (ë§¤ìš´ë§›)\n",
        "        scenario_1 = \"\"\"\n",
        "        ê³¼ëª©ëª…: ì°½ì—…ìº¡ìŠ¤í†¤ë””ìì¸ / ìˆ˜ì—…ê°œìš”: ë³¸ ìˆ˜ì—…ì€ 100% íŒ€ í”„ë¡œì íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n",
        "        í•™ìƒë“¤ì€ íŒ€ì„ êµ¬ì„±í•˜ì—¬ í•œ í•™ê¸° ë™ì•ˆ íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©°, ë§¤ì£¼ íŒ€ ë¯¸íŒ…ê³¼ íŒ€ ë³´ê³ ì„œ ì‘ì„±ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.\n",
        "        ì¤‘ê°„/ê¸°ë§ê³ ì‚¬ ì—†ì´ ì˜¤ì§ íŒ€ í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼ë¡œë§Œ ì„±ì ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "        íŒ€ì› ê°„ì˜ í˜‘ë ¥ì´ ë¬´ì—‡ë³´ë‹¤ ì¤‘ìš”í•˜ë©°, ê°œì¸ ê³¼ì œëŠ” ì—†ìŠµë‹ˆë‹¤.\n",
        "        \"\"\"\n",
        "\n",
        "        # [Scenario 2] íŒ€í”Œ X, ê³¼ì œ ë³´í†µ\n",
        "        scenario_2 = \"\"\"\n",
        "        ê³¼ëª©ëª…: ì„œì–‘ì² í•™ì‚¬ / ìˆ˜ì—…ê°œìš”: ê³ ëŒ€ë¶€í„° í˜„ëŒ€ê¹Œì§€ ì„œì–‘ ì² í•™ì˜ íë¦„ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "        ìˆ˜ì—…ì€ êµìˆ˜ë‹˜ì˜ ê°•ì˜ ìœ„ì£¼ë¡œ ì§„í–‰ë˜ë©°, ë³„ë„ì˜ ì¡°ë³„ ëª¨ì„ì€ ì—†ìŠµë‹ˆë‹¤.\n",
        "        í‰ê°€ëŠ” ì¤‘ê°„ê³ ì‚¬ 40%, ê¸°ë§ê³ ì‚¬ 40%, ê·¸ë¦¬ê³  ì¶œì„ 20%ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n",
        "        ê³¼ì œëŠ” í•™ê¸° ì¤‘ 1íšŒì˜ ê°œì¸ ë…í›„ê° ì œì¶œì´ ìˆìŠµë‹ˆë‹¤.\n",
        "        \"\"\"\n",
        "\n",
        "        # [Scenario 3] íŒ€í”Œ X, ê³¼ì œ ë§¤ìš° ì ìŒ (ê¿€ê°•)\n",
        "        scenario_3 = \"\"\"\n",
        "        ê³¼ëª©ëª…: ì˜í™” ê°ìƒê³¼ ë¹„í‰ / ìˆ˜ì—…ê°œìš”: ë§¤ì£¼ ì˜í™”ë¥¼ ê°ìƒí•˜ê³  ììœ ë¡­ê²Œ ê°ìƒí‰ì„ ë‚˜ëˆ„ëŠ” ìˆ˜ì—…ì…ë‹ˆë‹¤.\n",
        "        ì¤‘ê°„ê³ ì‚¬ì™€ ê¸°ë§ê³ ì‚¬ëŠ” ì—†ìœ¼ë©°, ìˆ˜ì—… ì°¸ì—¬ë„ì™€ ê°„ë‹¨í•œ ê°ìƒë¬¸ 1íšŒë¡œ ì„±ì ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "        ì¡°ë³„ ê³¼ì œë‚˜ ë°œí‘œëŠ” ì¼ì ˆ ì—†ìŠµë‹ˆë‹¤. ë¶€ë‹´ ì—†ì´ ì˜í™”ë¥¼ ì¦ê¸°ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "        \"\"\"\n",
        "\n",
        "        scenarios = [scenario_1, scenario_2, scenario_3]\n",
        "\n",
        "        for i, text in enumerate(scenarios):\n",
        "            is_team, prob_team, burden = analyze_syllabus(tokenizer, model_cls, model_reg, text)\n",
        "\n",
        "            team_msg = \"ğŸš¨ íŒ€í”Œ ìˆìŒ\" if is_team == 1 else \"ğŸ€ íŒ€í”Œ ì—†ìŒ\"\n",
        "\n",
        "            # ë¶€ë‹´ ì ìˆ˜ í•´ì„\n",
        "            if burden > 50: burden_msg = \"ë§¤ìš° ë†’ìŒ (ìˆ˜ê°• ì£¼ì˜)\"\n",
        "            elif burden > 20: burden_msg = \"ë³´í†µ\"\n",
        "            else: burden_msg = \"ë§¤ìš° ë‚®ìŒ (ê¿€ê°•)\"\n",
        "\n",
        "            print(f\"\\n[Scenario {i+1}]\")\n",
        "            print(f\"ğŸ“„ ë‚´ìš©: {text.strip().split('/')[1][:40]}...\")\n",
        "            print(f\"ğŸ¤– íŒ€í”Œ ì˜ˆì¸¡: {team_msg} (í™•ë¥ : {prob_team:.1f}%)\")\n",
        "            print(f\"ğŸ“‰ ê³¼ì œ ë¶€ë‹´: {burden:.1f}ì  -> {burden_msg}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. Google Drive IDë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRjndJlgE-sb",
        "outputId": "71706fd6-6365-4b2b-a663-3d50567f1dc5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ model.pt ë‹¤ìš´ë¡œë“œ ì¤‘... (ID: 1hcl250N4eFpdCpxIZlJNLQAv5FJpUvRX)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1hcl250N4eFpdCpxIZlJNLQAv5FJpUvRX\n",
            "From (redirected): https://drive.google.com/uc?id=1hcl250N4eFpdCpxIZlJNLQAv5FJpUvRX&confirm=t&uuid=e10f40bd-883a-43ad-9724-d2fa5643bf84\n",
            "To: /content/model.pt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114M/114M [00:01<00:00, 98.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ burden_model.pt ë‹¤ìš´ë¡œë“œ ì¤‘... (ID: 1fCQ8Qr_GxJtcqAn7l91_Bf64GdDfRyyC)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1fCQ8Qr_GxJtcqAn7l91_Bf64GdDfRyyC\n",
            "From (redirected): https://drive.google.com/uc?id=1fCQ8Qr_GxJtcqAn7l91_Bf64GdDfRyyC&confirm=t&uuid=cc4d3a15-7140-46e9-af26-dbe61c767966\n",
            "To: /content/burden_model.pt\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114M/114M [00:01<00:00, 74.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "â³ ëª¨ë¸ 2ê°œ ë¡œë”© ì¤‘...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at monologg/distilkobert and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at monologg/distilkobert and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
            "\n",
            "============================================================\n",
            "ğŸ“ HAT-N ìµœì¢… ë¶„ì„ (íŒ€í”Œ ìœ ë¬´ & ê³¼ì œ ë¶€ë‹´ ì˜ˆì¸¡)\n",
            "============================================================\n",
            "\n",
            "[Scenario 1]\n",
            "ğŸ“„ ë‚´ìš©:  ìˆ˜ì—…ê°œìš”: ë³¸ ìˆ˜ì—…ì€ 100% íŒ€ í”„ë¡œì íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤. \n",
            "  ...\n",
            "ğŸ¤– íŒ€í”Œ ì˜ˆì¸¡: ğŸš¨ íŒ€í”Œ ìˆìŒ (í™•ë¥ : 52.7%)\n",
            "ğŸ“‰ ê³¼ì œ ë¶€ë‹´: 18.7ì  -> ë§¤ìš° ë‚®ìŒ (ê¿€ê°•)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Scenario 2]\n",
            "ğŸ“„ ë‚´ìš©:  ìˆ˜ì—…ê°œìš”: ê³ ëŒ€ë¶€í„° í˜„ëŒ€ê¹Œì§€ ì„œì–‘ ì² í•™ì˜ íë¦„ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
            "     ...\n",
            "ğŸ¤– íŒ€í”Œ ì˜ˆì¸¡: ğŸ€ íŒ€í”Œ ì—†ìŒ (í™•ë¥ : 46.1%)\n",
            "ğŸ“‰ ê³¼ì œ ë¶€ë‹´: 13.1ì  -> ë§¤ìš° ë‚®ìŒ (ê¿€ê°•)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Scenario 3]\n",
            "ğŸ“„ ë‚´ìš©:  ìˆ˜ì—…ê°œìš”: ë§¤ì£¼ ì˜í™”ë¥¼ ê°ìƒí•˜ê³  ììœ ë¡­ê²Œ ê°ìƒí‰ì„ ë‚˜ëˆ„ëŠ” ìˆ˜ì—…ì…ë‹ˆë‹¤.\n",
            "...\n",
            "ğŸ¤– íŒ€í”Œ ì˜ˆì¸¡: ğŸ€ íŒ€í”Œ ì—†ìŒ (í™•ë¥ : 40.1%)\n",
            "ğŸ“‰ ê³¼ì œ ë¶€ë‹´: 19.8ì  -> ë§¤ìš° ë‚®ìŒ (ê¿€ê°•)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}